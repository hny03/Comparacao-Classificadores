df <- bean_df_bal %>%
group_by(Class)%>%
count(n())
ggplot(df, aes(x = Class, y = n, fill = Class)) +
geom_col() +
labs(title = "Distribuição das Classes de Feijão",
x = "Classe",
y = "Frequência") +
theme_minimal()
# Retirada das colunas fundamentais
bean_df <- bean_df_bal %>%
select(-c("MinorAxisLength", "MajorAxisLength", "Area", "Perimeter", "ConvexArea"))
min_max_normalization <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# Aplicando normalização (re-escala) nas colunas numéricas
bean_df_res <- bean_df %>%
mutate(across(c("AspectRation", "Eccentricity", "EquivDiameter", "Extent", "Solidity", "roundness", "Compactness", "ShapeFactor1", "ShapeFactor2", "ShapeFactor3", "ShapeFactor4"), min_max_normalization))
bean_df_res %>%
select(
AspectRation,
Eccentricity,
EquivDiameter,
Extent,
Solidity,
roundness,
Compactness,
ShapeFactor1,
ShapeFactor2,
ShapeFactor3,
ShapeFactor4
)
padronization_norm <- function(x){
return((x-mean(x))/sd(x))
}
# Aplicando normalização (padronização) nas colunas numéricas
bean_df_pad <- bean_df %>%
mutate(across(c("AspectRation", "Eccentricity", "EquivDiameter", "Extent", "Solidity", "roundness", "Compactness", "ShapeFactor1", "ShapeFactor2", "ShapeFactor3", "ShapeFactor4"), padronization_norm))
bean_df_pad %>%
select(
AspectRation,
Eccentricity,
EquivDiameter,
Extent,
Solidity,
roundness,
Compactness,
ShapeFactor1,
ShapeFactor2,
ShapeFactor3,
ShapeFactor4
)
glass_df <- glass_df %>%
select(-Id_number)
glass_df_res <- glass_df %>%
mutate(across(c("RI","Na","Mg","Al","Si","K","Ca","Ba","Fe"), min_max_normalization))
glass_df_res %>%
select(-Class)
glass_df_pad <- glass_df %>%
mutate(across(c("RI","Na","Mg","Al","Si","K","Ca","Ba","Fe"), padronization_norm))
glass_df_pad %>%
select(-Class)
library(class)
library(dplyr)
set.seed(42) # Reprodutibilidade
stopifnot(exists("bean_df_res")) # Verifica se o dataset existe
target_col <- "Class"
stopifnot(target_col %in% names(bean_df_res)) # Verifica se a classe existe
bean_df_res[[target_col]] <- as.factor(bean_df_res[[target_col]]) # Garante que a classe é factor
split_ratio <- 0.66 # Define o tamanho da partição
# Índices por classe
idx_treino <- bean_df_bal %>%
mutate(row_id = dplyr::row_number()) %>%
group_by(.data[[target_col]]) %>%
slice_sample(prop = split_ratio) %>% # Realiza a partição da base para treino e teste
pull(row_id)
train_df <- bean_df_bal[idx_treino, ]
test_df  <- bean_df_bal[-idx_treino, ]
# Matriz de preditores (x) e vetores de classe (y)
X_train <- train_df %>% select(-all_of(target_col)) %>% as.data.frame()
X_test  <- test_df  %>% select(-all_of(target_col)) %>% as.data.frame()
y_train <- train_df[[target_col]]
y_test  <- test_df[[target_col]]
stopifnot(is.factor(y_train), is.factor(y_test)) # Verifica se todos os valores são factor (exigido pelo KNN)
nrow(bean_df_bal)
nrow(bean_df)
bean_df <- read_excel("Dry_Bean_Dataset.xlsx")
bean_df <- as.data.table(bean_df)   # se quiser table/dt
nrow(bean_df)
13611*0,3
13611*0.3
nrow(glass_df)
500/13611
13611*0.03
3/100
library(readxl)
library(data.table)
library(ggplot2)
library(dplyr)
library(readxl)
library(data.table)
library(ggplot2)
library(dplyr)
library(ggplot2)
bean_df <- read_excel("Dry_Bean_Dataset.xlsx")
bean_df <- as.data.table(bean_df)   # se quiser table/dt
df <- bean_df %>%
group_by(Class)%>%
count(n())
ggplot(df, aes(x = Class, y = n, fill = Class)) +
geom_col() +
labs(title = "Distribuição das Classes de Feijão",
x = "Classe",
y = "Frequência") +
theme_minimal()
glass_df <- fread("glass.data", sep = ",", header = FALSE)
colnames(glass_df) <- c(
"Id_number",
"RI",  # V2
"Na",               # V3
"Mg",               # V4
"Al",               # V5
"Si",               # V6
"K",                # V7
"Ca",               # V8
"Ba",               # V9
"Fe",               # V10
"Class"             # V11
)
df <- glass_df %>%
group_by(Class)%>%
count(n()) %>%
mutate(Class = recode(Class,
`1` = "Janelas de edifícios (float)",
`2` = "Janelas de edifícios (não-float)",
`3` = "Janelas de veículos (float)",
`4` = "Janelas de veículos (não-float)",   # não há amostras
`5` = "Recipientes",
`6` = "Utensílios de mesa",
`7` = "Faróis"
))
ggplot(df, aes(x = Class, y = n, fill = Class)) +
geom_col() +
labs(title = "Distribuição das Classes de Vidro",
x = "Classe",
y = "Frequência") +
theme_minimal()
# Amostragem estratificada
frac_global <- 0.03  # 3% do dataset
bean_df_bal <- bean_df %>%
group_by(.data[[target_col]]) %>%
slice_sample(prop = frac_global) %>%
ungroup()
# Amostragem estratificada
frac_global <- 0.03  # 3% do dataset
bean_df_bal <- bean_df %>%
group_by(.data[[target_col]]) %>%
slice_sample(prop = frac_global) %>%
ungroup()
bean_df_bal
bean_df
bean_df_bal <- bean_df %>%
group_by(.data[[target_col]]) %>%
slice_sample(prop = 0.03) %>%
ungroup()
bean_df
bean_df_bal <- bean_df %>%
group_by(Class) %>% partiçao da amostragem
bean_df_bal <- bean_df %>%
group_by(Class) %>% # partiçao da amostragem
slice_sample(prop = frac_global) %>%
ungroup()
# Garantia de manutenção das proporções
df <- bean_df_bal %>%
group_by(Class)%>%
count(n())
ggplot(df, aes(x = Class, y = n, fill = Class)) +
geom_col() +
labs(title = "Distribuição das Classes de Feijão",
x = "Classe",
y = "Frequência") +
theme_minimal()
# Retirada das colunas fundamentais
bean_df_bal <- bean_df_bal %>%
select(-c("MinorAxisLength", "MajorAxisLength", "Area", "Perimeter", "ConvexArea"))
min_max_normalization <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# Aplicando normalização (re-escala) nas colunas numéricas
bean_df_res <- bean_df_bal %>%
mutate(across(c("AspectRation", "Eccentricity", "EquivDiameter", "Extent", "Solidity", "roundness", "Compactness", "ShapeFactor1", "ShapeFactor2", "ShapeFactor3", "ShapeFactor4"), min_max_normalization))
bean_df_res %>%
select(
AspectRation,
Eccentricity,
EquivDiameter,
Extent,
Solidity,
roundness,
Compactness,
ShapeFactor1,
ShapeFactor2,
ShapeFactor3,
ShapeFactor4
)
padronization_norm <- function(x){
return((x-mean(x))/sd(x))
}
# Aplicando normalização (padronização) nas colunas numéricas
bean_df_pad <- bean_df_res %>%
mutate(across(c("AspectRation", "Eccentricity", "EquivDiameter", "Extent", "Solidity", "roundness", "Compactness", "ShapeFactor1", "ShapeFactor2", "ShapeFactor3", "ShapeFactor4"), padronization_norm))
bean_df_pad %>%
select(
AspectRation,
Eccentricity,
EquivDiameter,
Extent,
Solidity,
roundness,
Compactness,
ShapeFactor1,
ShapeFactor2,
ShapeFactor3,
ShapeFactor4
)
glass_df <- glass_df %>%
select(-Id_number)
glass_df_res <- glass_df %>%
mutate(across(c("RI","Na","Mg","Al","Si","K","Ca","Ba","Fe"), min_max_normalization))
glass_df_res %>%
select(-Class)
glass_df_pad <- glass_df %>%
mutate(across(c("RI","Na","Mg","Al","Si","K","Ca","Ba","Fe"), padronization_norm))
glass_df_pad %>%
select(-Class)
library(class)
library(dplyr)
set.seed(42) # Reprodutibilidade
stopifnot(exists("bean_df_res")) # Verifica se o dataset existe
target_col <- "Class"
stopifnot(target_col %in% names(bean_df_res)) # Verifica se a classe existe
bean_df_res[[target_col]] <- as.factor(bean_df_res[[target_col]]) # Garante que a classe é factor
split_ratio <- 0.66 # Define o tamanho da partição
# Índices por classe
idx_treino <- bean_df_res %>%
mutate(row_id = dplyr::row_number()) %>%
group_by(.data[[target_col]]) %>%
slice_sample(prop = split_ratio) %>% # Realiza a partição da base para treino e teste
pull(row_id)
train_df <- bean_df_res[idx_treino, ]
test_df  <- bean_df_res[-idx_treino, ]
# Matriz de preditores (x) e vetores de classe (y)
X_train <- train_df %>% select(-all_of(target_col)) %>% as.data.frame()
X_test  <- test_df  %>% select(-all_of(target_col)) %>% as.data.frame()
y_train <- train_df[[target_col]]
y_test  <- test_df[[target_col]]
stopifnot(is.factor(y_t-rain), is.factor(y_test)) # Verifica se todos os valores são factor (exigido pelo KNN)
library(class)
library(dplyr)
set.seed(42) # Reprodutibilidade
stopifnot(exists("bean_df_res")) # Verifica se o dataset existe
target_col <- "Class"
stopifnot(target_col %in% names(bean_df_res)) # Verifica se a classe existe
bean_df_res[[target_col]] <- as.factor(bean_df_res[[target_col]]) # Garante que a classe é factor
split_ratio <- 0.66 # Define o tamanho da partição
# Índices por classe
idx_treino <- bean_df_res %>%
mutate(row_id = dplyr::row_number()) %>%
group_by(.data[[target_col]]) %>%
slice_sample(prop = split_ratio) %>% # Realiza a partição da base para treino e teste
pull(row_id)
train_df <- bean_df_res[idx_treino, ]
test_df  <- bean_df_res[-idx_treino, ]
# Matriz de preditores (x) e vetores de classe (y)
X_train <- train_df %>% select(-all_of(target_col)) %>% as.data.frame()
X_test  <- test_df  %>% select(-all_of(target_col)) %>% as.data.frame()
y_train <- train_df[[target_col]]
y_test  <- test_df[[target_col]]
stopifnot(is.factor(y_train), is.factor(y_test)) # Verifica se todos os valores são factor (exigido pelo KNN)
stopifnot(all(sapply(X_train, is.numeric)), all(sapply(X_test, is.numeric))) # Verifica se todos os valores são numéricos (exigido pelo KNN)
# Executar KNN
k <- 5 # Define a quantidade de K-vizinhos mais próximos
pred_k <- knn(
train = X_train,   # base de treino (preditores)
test  = X_test,    # base de teste  (preditores)
cl    = y_train,   # classes de treino (factor)
k     = k          # número de vizinhos
)
# Avaliar (matriz de confusão e acurácia)
conf_k <- table(Predito = pred_k, Real = y_test)
acc_k  <- mean(pred_k == y_test)
conf_k
acc_k
library(class)
library(dplyr)
set.seed(42) # Reprodutibilidade
stopifnot(exists("glass_df_res")) # Verifica se o dataset existe
target_col <- "Class"
stopifnot(target_col %in% names(glass_df_res)) # Verifica se a classe existe
glass_df_res[[target_col]] <- as.factor(glass_df_res[[target_col]]) # Garante que a classe é factor
split_ratio <- 0.66 # Define o tamanho da partição
# Índices por classe
idx_treino <- glass_df_res %>%
mutate(row_id = dplyr::row_number()) %>%
group_by(.data[[target_col]]) %>%
slice_sample(prop = split_ratio) %>% # Realiza a partição da base para treino e teste
pull(row_id)
train_df <- glass_df_res[idx_treino, ]
test_df  <- glass_df_res[-idx_treino, ]
# Matriz de preditores (x) e vetores de classe (y)
X_train <- train_df %>% select(-all_of(target_col)) %>% as.data.frame()
X_test  <- test_df  %>% select(-all_of(target_col)) %>% as.data.frame()
y_train <- train_df[[target_col]]
y_test  <- test_df[[target_col]]
stopifnot(is.factor(y_train), is.factor(y_test)) # Verifica se todos os valores são factor (exigido pelo KNN)
stopifnot(all(sapply(X_train, is.numeric)), all(sapply(X_test, is.numeric))) # Verifica se todos os valores são numéricos (exigido pelo KNN)
# Executar KNN
k <- 5 # Define a quantidade de K-vizinhos mais próximos
pred_k <- knn(
train = X_train,
test  = X_test,
cl    = y_train,
k     = k,
)
# Avaliar (matriz de confusão e acurácia)
conf_k <- table(Predito = pred_k, Real = y_test)
acc_k  <- mean(pred_k == y_test)
conf_k
acc_k
?slice_sample
install.packages("nnet")
library(nnet)
glass_df_pad
head(glass_df_pad)
model <- multinom(Class ~ RI + Na + Mg + Al + Si + K + Ca + Ba + Fe, data = glass_df_pad)
summary(model)
coefs <- summary(model)$coefficients
erros <- summary(model)$standard.errors
# Calcular estatísticas z e p-valores
z_values <- coefs / erros
p_values <- 2 * (1 - pnorm(abs(z_values)))  # Teste bilateral
split_ratio <- 0.66 # Define o tamanho da partição
idx_treino <- glass_df_pad %>%
group_by(Class) %>%
slice_sample(prop = split_ratio) # Realiza a partição da base para treino e teste
idx_teste <- glass_df_pad %>%
anti_join(idx_treino)
model <- multinom(Class ~ RI + Na + Mg + Al + Si + K + Ca + Ba + Fe, data = idx_treino)
summary(model)
coefs <- summary(model)$coefficients
erros <- summary(model)$standard.errors
# Calcular estatísticas z e p-valores
z_values <- coefs / erros
p_values <- 2 * (1 - pnorm(abs(z_values)))  # Teste bilateral
prediction <- predict(model, newdata = idx_teste)
prediction
head(prediction)
prediction
idx_teste
idx_teste$Class
prediction
head(bean_df_pad)
set.seed(123)
head(bean_df_pad)
# Definido partição de treino
split_ratio <- 0.66 # Define o tamanho da partição
idx_treino <- bean_df_pad %>%
group_by(Class) %>%
slice_sample(prop = split_ratio) # Realiza a partição da base para treino e teste
idx_teste <- bean_df_pad %>%
anti_join(idx_treino)
model <- multinom(Class ~ AspectRation + Eccentricity + EquivDiameter + Extent + Solidity + roundess + Compactness + ShapeFactor1 + ShapeFactor2 + ShapeFactor3 + ShapeFactor4, data = idx_treino)
head(bean_df_pad)
idx_treino
model <- multinom(Class ~ AspectRation + Eccentricity + EquivDiameter + Extent + Solidity + roundness + Compactness + ShapeFactor1 + ShapeFactor2 + ShapeFactor3 + ShapeFactor4, data = idx_treino)
set.seed(123)
head(bean_df_pad)
# Definido partição de treino
split_ratio <- 0.66 # Define o tamanho da partição
idx_treino <- bean_df_pad %>%
group_by(Class) %>%
slice_sample(prop = split_ratio) # Realiza a partição da base para treino e teste
idx_teste <- bean_df_pad %>%
anti_join(idx_treino)
model <- multinom(Class ~ AspectRation + Eccentricity + EquivDiameter + Extent + Solidity + roundness + Compactness + ShapeFactor1 + ShapeFactor2 + ShapeFactor3 + ShapeFactor4, data = idx_treino)
summary(model)
coefs <- summary(model)$coefficients
erros <- summary(model)$standard.errors
# Calcular estatísticas z e p-valores
z_values <- coefs / erros
p_values <- 2 * (1 - pnorm(abs(z_values)))  # Teste bilateral
# Mostrar os p-valores
print(p_values)
prediction <- predict(model, newdata = idx_teste)
idx_teste$Class
head(prediction)
prediction
View(glass_df)
View(glass_df)
View(glass_df_res)
library(readr)
library(read)
library(readr)
library(rpart)
library(caret)
# Carregar o dataset pré-processado
# Especificar os tipos de coluna para garantir que Class seja lido corretamente como numérico
glass_data <- read_csv(glass_preprocessed_path, col_types = cols(
RI = col_double(),
Na = col_double(),
Mg = col_double(),
Al = col_double(),
Si = col_double(),
K = col_double(),
Ca = col_double(),
Ba = col_double(),
Fe = col_double(),
Class = col_double() # Ler como double primeiro
))
library(readr)
library(rpart)
library(caret)
# Carregar o dataset pré-processado
# Especificar os tipos de coluna para garantir que Class seja lido corretamente como numérico
glass_data <- read_csv(glass_df_res, col_types = cols(
RI = col_double(),
Na = col_double(),
Mg = col_double(),
Al = col_double(),
Si = col_double(),
K = col_double(),
Ca = col_double(),
Ba = col_double(),
Fe = col_double(),
Class = col_double() # Ler como double primeiro
))
library(dplyr)
library(rpart)
library(caret)
set.seed(42)  # reprodutibilidade
# 0) Conferências do dataset pré-processado ----------------------------------
stopifnot(exists("glass_df_res"))
# Detecta automaticamente o nome da coluna-alvo entre opções comuns
target_col <- "Class"
# Garante que a classe é fator
glass_df_res[[target_col]] <- as.factor(glass_df_res[[target_col]])
# 1) Split estratificado (Holdout 2/3 treino, 1/3 teste) --------------------
split_ratio <- 2/3  # 0.66, como você descreveu no relatório
idx_treino <- glass_df_res %>%
mutate(row_id = dplyr::row_number()) %>%
group_by(.data[[target_col]]) %>%
slice_sample(prop = split_ratio) %>%
pull(row_id)
train_df <- glass_df_res[idx_treino, ]
test_df  <- glass_df_res[-idx_treino, ]
# 2) Fórmula: alvo ~ todos os preditores ------------------------------------
form <- reformulate(setdiff(names(train_df), target_col), response = target_col)
# 3) Treinar duas árvores com cp diferentes ---------------------------------
tree_cp_001  <- rpart(form, data = train_df, method = "class", control = rpart.control(cp = 0.01))
tree_cp_0005 <- rpart(form, data = train_df, method = "class", control = rpart.control(cp = 0.005))
# 4) Prever no conjunto de teste --------------------------------------------
pred_001  <- predict(tree_cp_001,  newdata = test_df, type = "class")
pred_0005 <- predict(tree_cp_0005, newdata = test_df, type = "class")
# 5) Avaliar (matriz de confusão e acurácia) --------------------------------
cm_001  <- confusionMatrix(pred_001,  test_df[[target_col]])
cm_0005 <- confusionMatrix(pred_0005, test_df[[target_col]])
acc_001  <- cm_001$overall["Accuracy"]
acc_0005 <- cm_0005$overall["Accuracy"]
cat("\n---------------------- Árvore (cp = 0.01) ----------------------\n")
print(cm_001)
cat(sprintf("\nAcurácia (cp=0.01): %.4f\n", acc_001))
cat("\n--------------------- Árvore (cp = 0.005) ----------------------\n")
print(cm_0005)
cat(sprintf("\nAcurácia (cp=0.005): %.4f\n", acc_0005))
library(dplyr)
library(rpart)
library(caret)
set.seed(42)  # reprodutibilidade
# 0) Conferências do dataset pré-processado ----------------------------------
stopifnot(exists("glass_df_res"))
# Detecta automaticamente o nome da coluna-alvo entre opções comuns
target_col <- "Class"
# Garante que a classe é fator
glass_df_res[[target_col]] <- as.factor(glass_df_res[[target_col]])
# 1) Split estratificado (Holdout 2/3 treino, 1/3 teste) --------------------
split_ratio <- 2/3  # 0.66, como você descreveu no relatório
idx_treino <- glass_df_res %>%
mutate(row_id = dplyr::row_number()) %>%
group_by(.data[[target_col]]) %>%
slice_sample(prop = split_ratio) %>%
pull(row_id)
train_df <- glass_df_res[idx_treino, ]
test_df  <- glass_df_res[-idx_treino, ]
# 2) Fórmula: alvo ~ todos os preditores ------------------------------------
form <- reformulate(setdiff(names(train_df), target_col), response = target_col)
# 3) Treinar duas árvores com cp diferentes ---------------------------------
tree_cp_001  <- rpart(form, data = train_df, method = "class", control = rpart.control(cp = 0.01))
tree_cp_0005 <- rpart(form, data = train_df, method = "class", control = rpart.control(cp = 0.005))
# 4) Prever no conjunto de teste --------------------------------------------
pred_001  <- predict(tree_cp_001,  newdata = test_df, type = "class")
pred_0005 <- predict(tree_cp_0005, newdata = test_df, type = "class")
# 5) Avaliar (matriz de confusão e acurácia) --------------------------------
cm_001  <- confusionMatrix(pred_001,  test_df[[target_col]])
cm_0005 <- confusionMatrix(pred_0005, test_df[[target_col]])
acc_001  <- cm_001$overall["Accuracy"]
acc_0005 <- cm_0005$overall["Accuracy"]
cat("\n---------------------- Árvore (cp = 0.01) ----------------------\n")
print(cm_001)
cat(sprintf("\nAcurácia (cp=0.01): %.4f\n", acc_001))
cat("\n--------------------- Árvore (cp = 0.005) ----------------------\n")
print(cm_0005)
cat(sprintf("\nAcurácia (cp=0.005): %.4f\n", acc_0005))
