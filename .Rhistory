max_values <- apply(coefs_abs, 1, max)
# Agora associamos os valores máximos às variáveis (colunas)
max_vars <- apply(coefs_abs, 1, function(x) names(x)[which.max(x)])
# Criar um data frame para mostrar os atributos associados aos maiores valores
important_vars <- data.frame(Variable = max_vars, MaxValue = max_values)
# Ordenar pelas variáveis com maior coeficiente absoluto
important_vars_sorted <- important_vars[order(-important_vars$MaxValue), ]
# Mostrar as variáveis mais importantes
head(important_vars_sorted)
model_less_att <- multinom(Class ~ Mg + Al + K, data = train_rl_glass)
coefs_less_att <- summary(model_less_att)$coefficients # pesos atribuidos a cada atributo de acordo com a classe
prediction_rl_glass_less_att <- predict(model_less_att, newdata = test_rl_glass)
# -------------------- Árvore de Decisão --------------------
# Avaliar | cp (p1) = 0.05
conf_p1_dt_glass  <- confusionMatrix(pred_p1_dt_glass,  test_dt_glass$Class)
acc_p1_dt_glass  <- mean(pred_p1_dt_glass == test_dt_glass$Class)
# Avaliar | cp (p2) = 0.001
conf_p2_dt_glass <- confusionMatrix(pred_p2_dt_glass, test_dt_glass$Class)
acc_p2_dt_glass <- mean(pred_p2_dt_glass == test_dt_glass$Class)
print(paste("A acurácia do dataset GLASS IDENTIFICATION é superior com cp = ",
ifelse(acc_p1_dt_glass > acc_p2_dt_glass, 0.05, 0.001)
)
)
# -------------------- KNN --------------------
# Avaliar | k (p1) = 3
conf_k_p1_knn_glass <- confusionMatrix(pred_k_p1_knn_glass, y_test_knn_glass)
acc_k_p1_knn_glass  <- mean(pred_k_p1_knn_glass == y_test_knn_glass)
# Avaliar | k (p2) = 5
conf_k_p2_knn_glass <- confusionMatrix(pred_k_p2_knn_glass, y_test_knn_glass)
acc_k_p2_knn_glass  <- mean(pred_k_p2_knn_glass == y_test_knn_glass)
print(paste("A acurácia do dataset GLASS IDENTIFICATION é superior com knn = ",
ifelse(acc_k_p2_knn_glass > acc_k_p1_knn_glass, 5, 3)
)
)
# -------------------- Regressão Logística --------------------
# Avaliar | todas as classes
conf_rl_glass <- confusionMatrix(prediction_rl_glass, test_rl_glass$Class)
acc_rl_glass  <- mean(prediction_rl_glass == test_rl_glass$Class)
# Avaliar | apenas classes mais importantes (baseado no modelo que usa todas as classes)
conf_rl_glass_less_att <- confusionMatrix(prediction_rl_glass_less_att,test_rl_glass$Class)
acc_rl_glass_less_att  <- mean(prediction_rl_glass_less_att == test_rl_glass$Class)
print(paste("A acurácia do dataset GLASS IDENTIFICATION é superior considerando ",
ifelse(acc_rl_glass > acc_rl_glass_less_att, "todos os atributos", "apenas os atributos selecionados")
)
)
# Função utilizada para criação das matrizes de confusão
plot_matrix <- function(data, nome){
ggplot(data, aes(x = Reference, y = Prediction, fill = Freq)) +
geom_tile() +
facet_wrap(~ model) + # Adiciona uma faceta para cada modelo
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = paste("Matrizes de Confusão ", nome, sep = ""), x = "Classe Real", y = "Classe Predita")
}
# -------------------- Acurácia --------------------
comparative_table_bean <- data.frame(
Dataset = "Dry Bean",
Classificator = c("Árvore de Decisão", "KNN", "Regressão Logística"),
Accuracy = c(acc_p2_dt_bean,acc_k_p2_knn_bean, acc_rl_bean_less_att)
)
comparative_table_bean
# -------------------- Matriz de Confusão --------------------
# Extrair os dados da matriz de confusão e definir modelos
cm_dt_bean <- as.data.frame(conf_p2_dt_bean$table)
cm_dt_bean$model <- "Árvore de Decisão"
cm_knn_bean <- as.data.frame(conf_k_p1_knn_bean$table)
cm_knn_bean$model <- "KNN"
cm_rl_bean <- as.data.frame(conf_rl_bean$table)
cm_rl_bean$model <- "Regressão Logística"
# Combinar as matrizes de confusão
cm_beans <- rbind(cm_dt_bean, cm_knn_bean, cm_rl_bean)
# Plotar as matrizes de confusão
plot_matrix(cm_dt_bean, "Dry Beans")
plot_matrix(cm_knn_bean, "Dry Beans")
plot_matrix(cm_rl_bean, "Dry Beans")
# -------------------- Acurácia --------------------
comparative_table_glass <- data.frame(
Dataset = "Glass Identification",
Classificator = c("Árvore de Decisão", "KNN", "Regressão Logística"),
Accuracy = c(acc_p2_dt_glass,acc_k_p1_knn_glass, acc_rl_glass)
)
comparative_table_glass
# -------------------- Matriz de Confusão --------------------
# Extrair os dados da matriz de confusão e definir modelos
cm_dt_glass <- as.data.frame(conf_p2_dt_glass$table)
cm_dt_glass$model <- "Árvore de Decisão"
cm_knn_glass <- as.data.frame(conf_k_p1_knn_glass$table)
cm_knn_glass$model <- "KNN"
cm_rl_glass <- as.data.frame(conf_rl_glass$table)
cm_rl_glass$model <- "Regressão Logística"
# Combinar as matrizes de confusão
cm_glasss <- rbind(cm_dt_glass, cm_knn_glass, cm_rl_glass)
# Plotar as matrizes de confusão
plot_matrix(cm_dt_glass, "Glass identification")
plot_matrix(cm_knn_glass, "Glass identification")
plot_matrix(cm_rl_glass, "Glass identification")
#| include: false
options(width = 70)                     # largura do console
knitr::opts_chunk$set(max.print = 100)  # limita impressão gigante
library(readxl)
library(data.table)
library(ggplot2)
library(dplyr)
library(nnet)
library(rpart)
library(caret)
library(class)
bean_df <- read_excel("Dry_Bean_Dataset.xlsx")
bean_df <- as.data.table(bean_df)   # se quiser table/dt
df <- bean_df %>%
group_by(Class)%>%
count(n())
ggplot(df, aes(x = Class, y = n, fill = Class)) +
geom_col() +
labs(title = "Distribuição das Classes de Feijão",
x = "Classe",
y = "Frequência") +
theme_minimal()
glass_df <- fread("glass.data", sep = ",", header = FALSE)
colnames(glass_df) <- c(
"Id_number",
"RI",  # V2
"Na",               # V3
"Mg",               # V4
"Al",               # V5
"Si",               # V6
"K",                # V7
"Ca",               # V8
"Ba",               # V9
"Fe",               # V10
"Class"             # V11
)
df <- glass_df %>%
group_by(Class)%>%
count(n()) %>%
mutate(Class = recode(Class,
`1` = "Janelas de edifícios (float)",
`2` = "Janelas de edifícios (não-float)",
`3` = "Janelas de veículos (float)",
`4` = "Janelas de veículos (não-float)",   # não há amostras
`5` = "Recipientes",
`6` = "Utensílios de mesa",
`7` = "Faróis"
))
ggplot(df, aes(x = Class, y = n, fill = Class)) +
geom_col() +
labs(title = "Distribuição das Classes de Vidro",
x = "Classe",
y = "Frequência") +
theme_minimal()
frac_global <- 0.03  # define o tamanho da partição para 3% do dataset
bean_df_bal <- bean_df %>%
group_by(Class) %>%
slice_sample(prop = frac_global) %>% # realiza a partiçao da amostragem
ungroup()
# Garantia de manutenção das proporções
df <- bean_df_bal %>%
group_by(Class)%>%
count(n())
ggplot(df, aes(x = Class, y = n, fill = Class)) +
geom_col() +
labs(title = "Distribuição das Classes de Feijão",
x = "Classe",
y = "Frequência") +
theme_minimal()
set.seed(42)  # Reprodutibilidade
idx_treino_bean <- bean_df_bal %>%
mutate(row_id = dplyr::row_number()) %>%
group_by(Class) %>%
slice_sample(prop = 2/3) %>% # Realiza a partição da base para treino e teste
pull(row_id)
# Retirada das colunas fundamentais
bean_df_bal <- bean_df_bal %>%
select(-c("MinorAxisLength", "MajorAxisLength", "Area", "Perimeter", "ConvexArea"))
min_max_normalization <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# Aplicando normalização (re-escala) nas colunas numéricas
bean_df_res <- bean_df_bal %>%
mutate(across(c("AspectRation", "Eccentricity", "EquivDiameter", "Extent", "Solidity", "roundness", "Compactness", "ShapeFactor1", "ShapeFactor2", "ShapeFactor3", "ShapeFactor4"), min_max_normalization))
bean_df_res %>%
select(
AspectRation,
Eccentricity,
EquivDiameter,
Extent,
Solidity,
roundness,
Compactness,
ShapeFactor1,
ShapeFactor2,
ShapeFactor3,
ShapeFactor4
)
padronization_norm <- function(x){
return((x-mean(x))/sd(x))
}
# Aplicando normalização (padronização) nas colunas numéricas
bean_df_pad <- bean_df_res %>%
mutate(across(c("AspectRation", "Eccentricity", "EquivDiameter", "Extent", "Solidity", "roundness", "Compactness", "ShapeFactor1", "ShapeFactor2", "ShapeFactor3", "ShapeFactor4"), padronization_norm))
bean_df_pad %>%
select(
AspectRation,
Eccentricity,
EquivDiameter,
Extent,
Solidity,
roundness,
Compactness,
ShapeFactor1,
ShapeFactor2,
ShapeFactor3,
ShapeFactor4
)
set.seed(42) # Reprodutibilidade
stopifnot(exists("bean_df_res")) # Verifica se o dataset existe
stopifnot('Class' %in% names(bean_df_res)) # Verifica se a classe existe
bean_df_res$Class <- as.factor(bean_df_res$Class) # Garante que a classe é factor
# Armazena a parte de treino e base separada em idx_treino_bean
train_knn_bean <- bean_df_res[idx_treino_bean, ]
test_knn_bean  <- bean_df_res[-idx_treino_bean, ]
# Matriz de preditores (x) e vetores de classe (y)
X_train_knn_bean <- train_knn_bean %>%
select(-all_of('Class')) %>%
as.data.frame()
X_test_knn_bean  <- test_knn_bean %>%
select(-all_of('Class')) %>%
as.data.frame()
y_train_knn_bean <- train_knn_bean$Class
y_test_knn_bean <- test_knn_bean$Class
stopifnot(is.factor(y_train_knn_bean), is.factor(y_test_knn_bean)) # Verifica se todos os valores são factor (exigido pelo KNN)
stopifnot(all(sapply(X_train_knn_bean, is.numeric)), all(sapply(X_test_knn_bean, is.numeric))) # Verifica se todos os valores são numéricos (exigido pelo KNN)
# Executar KNN para k (p1) = 3
k_p1_knn_bean <- 3 # Define a quantidade de K-vizinhos mais próximos
pred_k_p1_knn_bean <- knn(
train = X_train_knn_bean,   # base de treino (preditores)
test  = X_test_knn_bean,    # base de teste  (preditores)
cl    = y_train_knn_bean,   # classes de treino (factor)
k     = k_p1_knn_bean       # número de vizinhos
)
# Executar KNN para k (p2) = 5
k_p2_knn_bean <- 5 # Define a quantidade de K-vizinhos mais próximos
pred_k_p2_knn_bean <- knn(
train = X_train_knn_bean,   # base de treino (preditores)
test  = X_test_knn_bean,    # base de teste  (preditores)
cl    = y_train_knn_bean,   # classes de treino (factor)
k     = k_p2_knn_bean        # número de vizinhos
)
# -------------------- KNN --------------------
# Avaliar | k (p1) = 3
conf_k_p1_knn_bean <- confusionMatrix(pred_k_p1_knn_bean, y_test_knn_bean)
acc_k_p1_knn_bean  <- mean(pred_k_p1_knn_bean == y_test_knn_bean)
# Avaliar | k (p2) = 5
conf_k_p2_knn_bean  <- confusionMatrix(pred_k_p2_knn_bean, y_test_knn_bean)
acc_k_p2_knn_bean   <- mean(pred_k_p2_knn_bean == y_test_knn_bean)
print(paste("A acurácia do dataset DRY BEAN é superior com knn = ",
ifelse(acc_k_p2_knn_bean > acc_k_p1_knn_bean, 5, 3)
)
)
acc_k_p1_knn_bean
acc_k_p2_knn_bean
set.seed(42)
# Armazena a parte de treino e base separada em idx_treino_bean
train_rl_bean <- bean_df_pad[idx_treino_bean, ]
#| include: false
options(width = 70)                     # largura do console
knitr::opts_chunk$set(max.print = 100)  # limita impressão gigante
library(readxl)
library(data.table)
library(ggplot2)
library(dplyr)
library(nnet)
library(rpart)
library(caret)
library(class)
bean_df <- read_excel("Dry_Bean_Dataset.xlsx")
bean_df <- as.data.table(bean_df)   # se quiser table/dt
df <- bean_df %>%
group_by(Class)%>%
count(n())
ggplot(df, aes(x = Class, y = n, fill = Class)) +
geom_col() +
labs(title = "Distribuição das Classes de Feijão",
x = "Classe",
y = "Frequência") +
theme_minimal()
glass_df <- fread("glass.data", sep = ",", header = FALSE)
colnames(glass_df) <- c(
"Id_number",
"RI",  # V2
"Na",               # V3
"Mg",               # V4
"Al",               # V5
"Si",               # V6
"K",                # V7
"Ca",               # V8
"Ba",               # V9
"Fe",               # V10
"Class"             # V11
)
df <- glass_df %>%
group_by(Class)%>%
count(n()) %>%
mutate(Class = recode(Class,
`1` = "Janelas de edifícios (float)",
`2` = "Janelas de edifícios (não-float)",
`3` = "Janelas de veículos (float)",
`4` = "Janelas de veículos (não-float)",   # não há amostras
`5` = "Recipientes",
`6` = "Utensílios de mesa",
`7` = "Faróis"
))
ggplot(df, aes(x = Class, y = n, fill = Class)) +
geom_col() +
labs(title = "Distribuição das Classes de Vidro",
x = "Classe",
y = "Frequência") +
theme_minimal()
set.seed(42) # Reprodutibilidade
frac_global <- 0.03  # define o tamanho da partição para 3% do dataset
bean_df_bal <- bean_df %>%
group_by(Class) %>%
slice_sample(prop = frac_global) %>% # realiza a partiçao da amostragem
ungroup()
# Garantia de manutenção das proporções
df <- bean_df_bal %>%
group_by(Class)%>%
count(n())
ggplot(df, aes(x = Class, y = n, fill = Class)) +
geom_col() +
labs(title = "Distribuição das Classes de Feijão",
x = "Classe",
y = "Frequência") +
theme_minimal()
set.seed(42) # Reprodutibilidade
idx_treino_bean <- bean_df_bal %>%
mutate(row_id = dplyr::row_number()) %>%
group_by(Class) %>%
slice_sample(prop = 2/3) %>% # Realiza a partição da base para treino e teste
pull(row_id)
# Retirada das colunas fundamentais
bean_df_bal <- bean_df_bal %>%
select(-c("MinorAxisLength", "MajorAxisLength", "Area", "Perimeter", "ConvexArea"))
min_max_normalization <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# Aplicando normalização (re-escala) nas colunas numéricas
bean_df_res <- bean_df_bal %>%
mutate(across(c("AspectRation", "Eccentricity", "EquivDiameter", "Extent", "Solidity", "roundness", "Compactness", "ShapeFactor1", "ShapeFactor2", "ShapeFactor3", "ShapeFactor4"), min_max_normalization))
bean_df_res %>%
select(
AspectRation,
Eccentricity,
EquivDiameter,
Extent,
Solidity,
roundness,
Compactness,
ShapeFactor1,
ShapeFactor2,
ShapeFactor3,
ShapeFactor4
)
padronization_norm <- function(x){
return((x-mean(x))/sd(x))
}
# Aplicando normalização (padronização) nas colunas numéricas
bean_df_pad <- bean_df_res %>%
mutate(across(c("AspectRation", "Eccentricity", "EquivDiameter", "Extent", "Solidity", "roundness", "Compactness", "ShapeFactor1", "ShapeFactor2", "ShapeFactor3", "ShapeFactor4"), padronization_norm))
bean_df_pad %>%
select(
AspectRation,
Eccentricity,
EquivDiameter,
Extent,
Solidity,
roundness,
Compactness,
ShapeFactor1,
ShapeFactor2,
ShapeFactor3,
ShapeFactor4
)
set.seed(42)  # Reprodutibilidade
bean_df_bal$Class <- as.factor(bean_df_bal$Class) # Garante que a classe é factor
# Armazena a parte de treino e base separada em idx_treino_bean
train_dt_bean <- bean_df_bal[idx_treino_bean, ]
test_dt_bean  <- bean_df_bal[-idx_treino_bean, ]
# Fórmula: alvo ~ todos os preditores
form_dt_bean <- reformulate(setdiff(names(train_dt_bean), 'Class'), response = 'Class')
# Executar Árvore de Decisão para cp (p1) = 0.05
cp_p1_dt_bean  <- rpart(form_dt_bean, data = train_dt_bean, method = "class", control = rpart.control(cp = 0.05))
pred_p1_dt_bean  <- predict(cp_p1_dt_bean,  newdata = test_dt_bean, type = "class")
# Executar Árvore de Decisão para cp (p2) = 0.001
cp_p2_dt_bean <- rpart(form_dt_bean, data = train_dt_bean, method = "class", control = rpart.control(cp = 0.001))
pred_p2_dt_bean <- predict(cp_p2_dt_bean, newdata = test_dt_bean, type = "class")
set.seed(42) # Reprodutibilidade
bean_df_res$Class <- as.factor(bean_df_res$Class) # Garante que a classe é factor
# Armazena a parte de treino e base separada em idx_treino_bean
train_knn_bean <- bean_df_res[idx_treino_bean, ]
test_knn_bean  <- bean_df_res[-idx_treino_bean, ]
# Matriz de preditores (x) e vetores de classe (y)
X_train_knn_bean <- train_knn_bean %>%
select(-all_of('Class')) %>%
as.data.frame()
X_test_knn_bean  <- test_knn_bean %>%
select(-all_of('Class')) %>%
as.data.frame()
y_train_knn_bean <- train_knn_bean$Class
y_test_knn_bean <- test_knn_bean$Class
stopifnot(is.factor(y_train_knn_bean), is.factor(y_test_knn_bean)) # Verifica se todos os valores são factor (exigido pelo KNN)
stopifnot(all(sapply(X_train_knn_bean, is.numeric)), all(sapply(X_test_knn_bean, is.numeric))) # Verifica se todos os valores são numéricos (exigido pelo KNN)
# Executar KNN para k (p1) = 3
k_p1_knn_bean <- 3 # Define a quantidade de K-vizinhos mais próximos
pred_k_p1_knn_bean <- knn(
train = X_train_knn_bean,   # base de treino (preditores)
test  = X_test_knn_bean,    # base de teste  (preditores)
cl    = y_train_knn_bean,   # classes de treino (factor)
k     = k_p1_knn_bean       # número de vizinhos
)
# Executar KNN para k (p2) = 5
k_p2_knn_bean <- 5 # Define a quantidade de K-vizinhos mais próximos
pred_k_p2_knn_bean <- knn(
train = X_train_knn_bean,   # base de treino (preditores)
test  = X_test_knn_bean,    # base de teste  (preditores)
cl    = y_train_knn_bean,   # classes de treino (factor)
k     = k_p2_knn_bean        # número de vizinhos
)
set.seed(42)
# Armazena a parte de treino e base separada em idx_treino_bean
train_rl_bean <- bean_df_pad[idx_treino_bean, ]
test_rl_bean  <- bean_df_pad[-idx_treino_bean, ]
model_rl_bean <- multinom(Class ~ AspectRation + Eccentricity + EquivDiameter + Extent + Solidity + roundness + Compactness + ShapeFactor1 + ShapeFactor2 + ShapeFactor3 + ShapeFactor4, data = train_rl_bean)
coefs <- summary(model_rl_bean)$coefficients # pesos atribuidos a cada atributo de acordo com a classe
prediction_rl_bean <- predict(model_rl_bean, newdata = test_rl_bean)
# Converter os coeficientes em um data frame para facilitar a manipulação
coefs_df <- as.data.frame(coefs)
# Calcular os coeficientes absolutos
coefs_abs <- abs(coefs_df)
# Para cada variável (linha), pegar o maior valor absoluto e associar à variável
max_values <- apply(coefs_abs, 1, max)
# Agora associamos os valores máximos às variáveis (colunas)
max_vars <- apply(coefs_abs, 1, function(x) names(x)[which.max(x)])
# Criar um data frame para mostrar os atributos associados aos maiores valores
important_vars <- data.frame(Variable = max_vars, MaxValue = max_values)
# Ordenar pelas variáveis com maior coeficiente absoluto
important_vars_sorted <- important_vars[order(-important_vars$MaxValue), ]
# Mostrar as variáveis mais importantes
head(important_vars_sorted)
model_rl_bean_less_att <- multinom(Class ~  EquivDiameter + roundness + ShapeFactor1 + ShapeFactor4, data = train_rl_bean)
coefs_bean_less_att <- summary(model_rl_bean_less_att)$coefficients # pesos atribuidos a cada atributo de acordo com a classe
prediction_rl_bean_less_att <- predict(model_rl_bean_less_att, newdata = test_rl_bean)
# -------------------- Árvore de Decisão --------------------
# Avaliar | cp (p1) = 0.05
conf_p1_dt_bean <- confusionMatrix(pred_p1_dt_bean,test_dt_bean$Class)
acc_p1_dt_bean <- mean(pred_p1_dt_bean == test_dt_bean$Class)
# Avaliar | cp (p2) = 0.001
conf_p2_dt_bean <- confusionMatrix(pred_p2_dt_bean,test_dt_bean$Class)
acc_p2_dt_bean <- mean(pred_p2_dt_bean == test_dt_bean$Class)
print(paste("A acurácia do dataset DRY BEAN é superior com cp = ",
ifelse(acc_p1_dt_bean > acc_p2_dt_bean, 0.05, 0.001)
)
)
# -------------------- KNN --------------------
# Avaliar | k (p1) = 3
conf_k_p1_knn_bean <- confusionMatrix(pred_k_p1_knn_bean, y_test_knn_bean)
acc_k_p1_knn_bean  <- mean(pred_k_p1_knn_bean == y_test_knn_bean)
# Avaliar | k (p2) = 5
conf_k_p2_knn_bean  <- confusionMatrix(pred_k_p2_knn_bean, y_test_knn_bean)
acc_k_p2_knn_bean   <- mean(pred_k_p2_knn_bean == y_test_knn_bean)
print(paste("A acurácia do dataset DRY BEAN é superior com knn = ",
ifelse(acc_k_p2_knn_bean > acc_k_p1_knn_bean, 5, 3)
)
)
# -------------------- Regressão Logística --------------------
# Avaliar | todas as classes
conf_rl_bean <- confusionMatrix(prediction_rl_bean, test_rl_bean$Class)
set.seed(42)
# Armazena a parte de treino e base separada em idx_treino_bean
train_rl_bean <- bean_df_res[idx_treino_bean, ]
test_rl_bean  <- bean_df_res[-idx_treino_bean, ]
model_rl_bean <- multinom(Class ~ AspectRation + Eccentricity + EquivDiameter + Extent + Solidity + roundness + Compactness + ShapeFactor1 + ShapeFactor2 + ShapeFactor3 + ShapeFactor4, data = train_rl_bean)
coefs <- summary(model_rl_bean)$coefficients # pesos atribuidos a cada atributo de acordo com a classe
prediction_rl_bean <- predict(model_rl_bean, newdata = test_rl_bean)
# Converter os coeficientes em um data frame para facilitar a manipulação
coefs_df <- as.data.frame(coefs)
# Calcular os coeficientes absolutos
coefs_abs <- abs(coefs_df)
# Para cada variável (linha), pegar o maior valor absoluto e associar à variável
max_values <- apply(coefs_abs, 1, max)
# Agora associamos os valores máximos às variáveis (colunas)
max_vars <- apply(coefs_abs, 1, function(x) names(x)[which.max(x)])
# Criar um data frame para mostrar os atributos associados aos maiores valores
important_vars <- data.frame(Variable = max_vars, MaxValue = max_values)
# Ordenar pelas variáveis com maior coeficiente absoluto
important_vars_sorted <- important_vars[order(-important_vars$MaxValue), ]
# Mostrar as variáveis mais importantes
head(important_vars_sorted)
model_rl_bean_less_att <- multinom(Class ~  EquivDiameter + roundness + ShapeFactor1 + ShapeFactor4, data = train_rl_bean)
coefs_bean_less_att <- summary(model_rl_bean_less_att)$coefficients # pesos atribuidos a cada atributo de acordo com a classe
prediction_rl_bean_less_att <- predict(model_rl_bean_less_att, newdata = test_rl_bean)
# -------------------- Regressão Logística --------------------
# Avaliar | todas as classes
conf_rl_bean <- confusionMatrix(prediction_rl_bean, test_rl_bean$Class)
acc_rl_bean  <- mean(prediction_rl_bean == test_rl_bean$Class)
# Avaliar | apenas classes mais importantes (baseado no modelo que usa todas as classes)
conf_rl_bean_less_att <- confusionMatrix(prediction_rl_bean_less_att,test_rl_bean$Class)
acc_rl_bean_less_att  <- mean(prediction_rl_bean_less_att == test_rl_bean$Class)
print(paste("A acurácia do dataset DRY BEAN é superior considerando ",
ifelse(acc_rl_bean > acc_rl_bean_less_att, "todos os atributos", "apenas os atributos selecionados")
)
)
