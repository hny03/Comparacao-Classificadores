group_by(Class)%>%
count(n()) %>%
mutate(Class = recode(Class,
`1` = "Janelas de edifícios (float)",
`2` = "Janelas de edifícios (não-float)",
`3` = "Janelas de veículos (float)",
`4` = "Janelas de veículos (não-float)",   # não há amostras
`5` = "Recipientes",
`6` = "Utensílios de mesa",
`7` = "Faróis"
))
ggplot(df, aes(x = Class, y = n, fill = Class)) +
geom_col() +
labs(title = "Distribuição das Classes de Vidro",
x = "Classe",
y = "Frequência") +
theme_minimal()
# Retirada das colunas fundamentais
bean_df <- bean_df %>%
select(-c("MinorAxisLength", "MajorAxisLength", "Area", "Perimeter", "ConvexArea"))
min_max_normalization <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# Aplicando normalização (re-escala) nas colunas numéricas
bean_df_res <- bean_df %>%
mutate(across(c("AspectRation", "Eccentricity", "EquivDiameter", "Extent", "Solidity", "roundness", "Compactness", "ShapeFactor1", "ShapeFactor2", "ShapeFactor3", "ShapeFactor4"), min_max_normalization))
bean_df_res %>%
select(
AspectRation,
Eccentricity,
EquivDiameter,
Extent,
Solidity,
roundness,
Compactness,
ShapeFactor1,
ShapeFactor2,
ShapeFactor3,
ShapeFactor4
)
padronization_norm <- function(x){
return((x-mean(x))/sd(x))
}
# Aplicando normalização (padronização) nas colunas numéricas
bean_df_pad <- bean_df %>%
mutate(across(c("AspectRation", "Eccentricity", "EquivDiameter", "Extent", "Solidity", "roundness", "Compactness", "ShapeFactor1", "ShapeFactor2", "ShapeFactor3", "ShapeFactor4"), padronization_norm))
bean_df_pad %>%
select(
AspectRation,
Eccentricity,
EquivDiameter,
Extent,
Solidity,
roundness,
Compactness,
ShapeFactor1,
ShapeFactor2,
ShapeFactor3,
ShapeFactor4
)
glass_df <- glass_df %>%
select(-Id_number)
glass_df_res <- glass_df %>%
mutate(across(c("RI","Na","Mg","Al","Si","K","Ca","Ba","Fe"), min_max_normalization))
glass_df_res %>%
select(-Class)
glass_df_pad <- glass_df %>%
mutate(across(c("RI","Na","Mg","Al","Si","K","Ca","Ba","Fe"), padronization_norm))
glass_df_pad %>%
select(-Class)
View(teste)
View(glass_df_res)
View(glass_df_pad)
View(glass_df)
View(df)
View(bean_df_res)
View(bean_df_pad)
View(bean_df_norm)
View(bean_df)
View(bean)
library(readxl)
library(data.table)
library(ggplot2)
library(dplyr)
library(ggplot2)
bean_df <- read_excel("Dry_Bean_Dataset.xlsx")
bean_df <- as.data.table(bean_df)   # se quiser table/dt
df <- bean_df %>%
group_by(Class)%>%
count(n())
ggplot(df, aes(x = Class, y = n, fill = Class)) +
geom_col() +
labs(title = "Distribuição das Classes de Feijão",
x = "Classe",
y = "Frequência") +
theme_minimal()
glass_df <- fread("glass.data", sep = ",", header = FALSE)
colnames(glass_df) <- c(
"Id_number",
"RI",  # V2
"Na",               # V3
"Mg",               # V4
"Al",               # V5
"Si",               # V6
"K",                # V7
"Ca",               # V8
"Ba",               # V9
"Fe",               # V10
"Class"             # V11
)
df <- glass_df %>%
group_by(Class)%>%
count(n()) %>%
mutate(Class = recode(Class,
`1` = "Janelas de edifícios (float)",
`2` = "Janelas de edifícios (não-float)",
`3` = "Janelas de veículos (float)",
`4` = "Janelas de veículos (não-float)",   # não há amostras
`5` = "Recipientes",
`6` = "Utensílios de mesa",
`7` = "Faróis"
))
ggplot(df, aes(x = Class, y = n, fill = Class)) +
geom_col() +
labs(title = "Distribuição das Classes de Vidro",
x = "Classe",
y = "Frequência") +
theme_minimal()
# Retirada das colunas fundamentais
bean_df <- bean_df %>%
select(-c("MinorAxisLength", "MajorAxisLength", "Area", "Perimeter", "ConvexArea"))
# Retirada das colunas fundamentais
bean_df <- bean_df %>%
select(-c("MinorAxisLength", "MajorAxisLength", "Area", "Perimeter", "ConvexArea"))
min_max_normalization <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# Aplicando normalização (re-escala) nas colunas numéricas
bean_df_res <- bean_df %>%
mutate(across(c("AspectRation", "Eccentricity", "EquivDiameter", "Extent", "Solidity", "roundness", "Compactness", "ShapeFactor1", "ShapeFactor2", "ShapeFactor3", "ShapeFactor4"), min_max_normalization))
bean_df_res %>%
select(
AspectRation,
Eccentricity,
EquivDiameter,
Extent,
Solidity,
roundness,
Compactness,
ShapeFactor1,
ShapeFactor2,
ShapeFactor3,
ShapeFactor4
)
padronization_norm <- function(x){
return((x-mean(x))/sd(x))
}
# Aplicando normalização (padronização) nas colunas numéricas
bean_df_pad <- bean_df %>%
mutate(across(c("AspectRation", "Eccentricity", "EquivDiameter", "Extent", "Solidity", "roundness", "Compactness", "ShapeFactor1", "ShapeFactor2", "ShapeFactor3", "ShapeFactor4"), padronization_norm))
bean_df_pad %>%
select(
AspectRation,
Eccentricity,
EquivDiameter,
Extent,
Solidity,
roundness,
Compactness,
ShapeFactor1,
ShapeFactor2,
ShapeFactor3,
ShapeFactor4
)
glass_df <- glass_df %>%
select(-Id_number)
glass_df_res <- glass_df %>%
mutate(across(c("RI","Na","Mg","Al","Si","K","Ca","Ba","Fe"), min_max_normalization))
glass_df_res %>%
select(-Class)
glass_df_pad <- glass_df %>%
mutate(across(c("RI","Na","Mg","Al","Si","K","Ca","Ba","Fe"), padronization_norm))
glass_df_pad %>%
select(-Class)
cls
clear
clean
View(bean_df)
View(df)
head(bean_dfr_res)
head(bean_df_res)
view(bean_df_res)
view(df)
head(glass_df)
head(bean_df)
View(glass_df)
View(bean_df_res)
library(class)
# Pacotes mínimos
library(class)   # knn()
library(dplyr)
set.seed(42)     # reprodutibilidade
# 0) Conferência rápida do objeto pré-processado -----------------------------
stopifnot(exists("bean_df_res"))
target_col <- "Class"
stopifnot(target_col %in% names(bean_df_res))
# Garante que a classe é factor
bean_df_res[[target_col]] <- as.factor(bean_df_res[[target_col]])
# 1) Separar treino e teste (estratificado simples) -------------------------
# Vamos fazer um split 70/30 preservando, tanto quanto possível, as proporções da classe.
# Para não adicionar dependências (caret), faremos uma amostragem estratificada simples.
split_ratio <- 0.7
# Índices por classe
idx_treino <- bean_df_res %>%
mutate(row_id = row_number()) %>%
group_by(.data[[target_col]]) %>%
slice_sample(prop = split_ratio) %>%
pull(row_id)
train_df <- bean_df_res[idx_treino, ]
test_df  <- bean_df_res[-idx_treino, ]
# Matriz de preditores (apenas colunas numéricas) e vetores de classe
X_train <- train_df %>% select(-all_of(target_col)) %>% as.data.frame()
X_test  <- test_df  %>% select(-all_of(target_col)) %>% as.data.frame()
y_train <- train_df[[target_col]]
y_test  <- test_df[[target_col]]
# Conferências úteis:
stopifnot(is.factor(y_train), is.factor(y_test))
stopifnot(all(sapply(X_train, is.numeric)), all(sapply(X_test, is.numeric)))
# 2) Escolher K e rodar o KNN ------------------------------------------------
k <- 5
pred_k <- knn(
train = X_train,   # base de treino (preditores)
test  = X_test,    # base de teste  (preditores)
cl    = y_train,   # classes de treino (factor)
k     = k          # número de vizinhos
)
# 3) Avaliar (matriz de confusão e acurácia) ---------------------------------
conf_k <- table(Predito = pred_k5, Real = y_test)
library(class)
# Pacotes mínimos
library(class)   # knn()
library(dplyr)
set.seed(42)     # reprodutibilidade
# 0) Conferência rápida do objeto pré-processado -----------------------------
stopifnot(exists("bean_df_res"))
target_col <- "Class"
stopifnot(target_col %in% names(bean_df_res))
# Garante que a classe é factor
bean_df_res[[target_col]] <- as.factor(bean_df_res[[target_col]])
# 1) Separar treino e teste (estratificado simples) -------------------------
# Vamos fazer um split 70/30 preservando, tanto quanto possível, as proporções da classe.
# Para não adicionar dependências (caret), faremos uma amostragem estratificada simples.
split_ratio <- 0.7
# Índices por classe
idx_treino <- bean_df_res %>%
mutate(row_id = row_number()) %>%
group_by(.data[[target_col]]) %>%
slice_sample(prop = split_ratio) %>%
pull(row_id)
train_df <- bean_df_res[idx_treino, ]
test_df  <- bean_df_res[-idx_treino, ]
# Matriz de preditores (apenas colunas numéricas) e vetores de classe
X_train <- train_df %>% select(-all_of(target_col)) %>% as.data.frame()
X_test  <- test_df  %>% select(-all_of(target_col)) %>% as.data.frame()
y_train <- train_df[[target_col]]
y_test  <- test_df[[target_col]]
# Conferências úteis:
stopifnot(is.factor(y_train), is.factor(y_test))
stopifnot(all(sapply(X_train, is.numeric)), all(sapply(X_test, is.numeric)))
# 2) Escolher K e rodar o KNN ------------------------------------------------
k <- 5
pred_k <- knn(
train = X_train,   # base de treino (preditores)
test  = X_test,    # base de teste  (preditores)
cl    = y_train,   # classes de treino (factor)
k     = k          # número de vizinhos
)
# 3) Avaliar (matriz de confusão e acurácia) ---------------------------------
conf_k <- table(Predito = pred_k, Real = y_test)
acc_k  <- mean(pred_k == y_test)
conf_k
acc_k
library(class)
# Pacotes mínimos
library(class)   # knn()
library(dplyr)
set.seed(42)     # reprodutibilidade
# 0) Conferência rápida do objeto pré-processado -----------------------------
stopifnot(exists("bean_df_res"))
target_col <- "Class"
stopifnot(target_col %in% names(bean_df_res))
# Garante que a classe é factor
bean_df_res[[target_col]] <- as.factor(bean_df_res[[target_col]])
# 1) Separar treino e teste (estratificado simples) -------------------------
# Vamos fazer um split 70/30 preservando, tanto quanto possível, as proporções da classe.
# Para não adicionar dependências (caret), faremos uma amostragem estratificada simples.
split_ratio <- 0.7
# Índices por classe
idx_treino <- bean_df_res %>%
mutate(row_id = row_number()) %>%
group_by(.data[[target_col]]) %>%
slice_sample(prop = split_ratio) %>%
pull(row_id)
train_df <- bean_df_res[idx_treino, ]
test_df  <- bean_df_res[-idx_treino, ]
# Matriz de preditores (apenas colunas numéricas) e vetores de classe
X_train <- train_df %>% select(-all_of(target_col)) %>% as.data.frame()
X_test  <- test_df  %>% select(-all_of(target_col)) %>% as.data.frame()
y_train <- train_df[[target_col]]
y_test  <- test_df[[target_col]]
# Conferências úteis:
stopifnot(is.factor(y_train), is.factor(y_test))
stopifnot(all(sapply(X_train, is.numeric)), all(sapply(X_test, is.numeric)))
# 2) Escolher K e rodar o KNN ------------------------------------------------
k <- 10
pred_k <- knn(
train = X_train,   # base de treino (preditores)
test  = X_test,    # base de teste  (preditores)
cl    = y_train,   # classes de treino (factor)
k     = k          # número de vizinhos
)
# 3) Avaliar (matriz de confusão e acurácia) ---------------------------------
conf_k <- table(Predito = pred_k, Real = y_test)
acc_k  <- mean(pred_k == y_test)
conf_k
acc_k
library(class)
# Pacotes mínimos
library(class)   # knn()
library(dplyr)
set.seed(42)     # reprodutibilidade
n_por_classe <- 800
bean_bal <- bean_df_res %>%
group_by(Class) %>%
slice_sample(n = min(n_por_classe, n())) %>%
ungroup()
library(class)
# Pacotes mínimos
library(class)   # knn()
library(dplyr)
set.seed(42)     # reprodutibilidade
n_por_classe <- 800
bean_bal <- bean_df_res %>%
group_by(Class) %>%
slice_sample(n = n_por_classe) %>%
ungroup()
# 0) Conferência rápida do objeto pré-processado -----------------------------
stopifnot(exists("bean_df_res"))
target_col <- "Class"
stopifnot(target_col %in% names(bean_df_res))
# Garante que a classe é factor
bean_df_res[[target_col]] <- as.factor(bean_df_res[[target_col]])
# 1) Separar treino e teste (estratificado simples) -------------------------
split_ratio <- 0.7
# Índices por classe
idx_treino <- bean_df_res %>%
mutate(row_id = row_number()) %>%
group_by(.data[[target_col]]) %>%
slice_sample(prop = split_ratio) %>%
pull(row_id)
train_df <- bean_df_res[idx_treino, ]
test_df  <- bean_df_res[-idx_treino, ]
# Matriz de preditores (apenas colunas numéricas) e vetores de classe
X_train <- train_df %>% select(-all_of(target_col)) %>% as.data.frame()
X_test  <- test_df  %>% select(-all_of(target_col)) %>% as.data.frame()
y_train <- train_df[[target_col]]
y_test  <- test_df[[target_col]]
# Conferências úteis:
stopifnot(is.factor(y_train), is.factor(y_test))
stopifnot(all(sapply(X_train, is.numeric)), all(sapply(X_test, is.numeric)))
# 2) Escolher K e rodar o KNN ------------------------------------------------
k <- 5
pred_k <- knn(
train = X_train,   # base de treino (preditores)
test  = X_test,    # base de teste  (preditores)
cl    = y_train,   # classes de treino (factor)
k     = k,          # número de vizinhos
ties  = "random"   # desempata aleatoriamente
)
library(class)
# Pacotes mínimos
library(class)   # knn()
library(dplyr)
set.seed(42)     # reprodutibilidade
n_por_classe <- 800
bean_bal <- bean_df_res %>%
group_by(Class) %>%
slice_sample(n = n_por_classe) %>%
ungroup()
# 0) Conferência rápida do objeto pré-processado -----------------------------
stopifnot(exists("bean_df_res"))
target_col <- "Class"
stopifnot(target_col %in% names(bean_df_res))
# Garante que a classe é factor
bean_df_res[[target_col]] <- as.factor(bean_df_res[[target_col]])
# 1) Separar treino e teste (estratificado simples) -------------------------
split_ratio <- 0.7
# Índices por classe
idx_treino <- bean_df_res %>%
mutate(row_id = row_number()) %>%
group_by(.data[[target_col]]) %>%
slice_sample(prop = split_ratio) %>%
pull(row_id)
train_df <- bean_df_res[idx_treino, ]
test_df  <- bean_df_res[-idx_treino, ]
# Matriz de preditores (apenas colunas numéricas) e vetores de classe
X_train <- train_df %>% select(-all_of(target_col)) %>% as.data.frame()
X_test  <- test_df  %>% select(-all_of(target_col)) %>% as.data.frame()
y_train <- train_df[[target_col]]
y_test  <- test_df[[target_col]]
# Conferências úteis:
stopifnot(is.factor(y_train), is.factor(y_test))
stopifnot(all(sapply(X_train, is.numeric)), all(sapply(X_test, is.numeric)))
# 2) Escolher K e rodar o KNN ------------------------------------------------
k <- 5
pred_k <- knn(
train = X_train,   # base de treino (preditores)
test  = X_test,    # base de teste  (preditores)
cl    = y_train,   # classes de treino (factor)
k     = k          # número de vizinhos
)
# 3) Avaliar (matriz de confusão e acurácia) ---------------------------------
conf_k <- table(Predito = pred_k, Real = y_test)
acc_k  <- mean(pred_k == y_test)
conf_k
acc_k
library(class)
# Pacotes mínimos
library(class)   # knn()
library(dplyr)
set.seed(42)     # reprodutibilidade
n_por_classe <- 500
bean_bal <- bean_df_res %>%
group_by(Class) %>%
slice_sample(n = n_por_classe) %>%
ungroup()
# 0) Conferência rápida do objeto pré-processado -----------------------------
stopifnot(exists("bean_df_res"))
target_col <- "Class"
stopifnot(target_col %in% names(bean_df_res))
# Garante que a classe é factor
bean_df_res[[target_col]] <- as.factor(bean_df_res[[target_col]])
# 1) Separar treino e teste (estratificado simples) -------------------------
split_ratio <- 0.7
# Índices por classe
idx_treino <- bean_df_res %>%
mutate(row_id = row_number()) %>%
group_by(.data[[target_col]]) %>%
slice_sample(prop = split_ratio) %>%
pull(row_id)
train_df <- bean_df_res[idx_treino, ]
test_df  <- bean_df_res[-idx_treino, ]
# Matriz de preditores (apenas colunas numéricas) e vetores de classe
X_train <- train_df %>% select(-all_of(target_col)) %>% as.data.frame()
X_test  <- test_df  %>% select(-all_of(target_col)) %>% as.data.frame()
y_train <- train_df[[target_col]]
y_test  <- test_df[[target_col]]
# Conferências úteis:
stopifnot(is.factor(y_train), is.factor(y_test))
stopifnot(all(sapply(X_train, is.numeric)), all(sapply(X_test, is.numeric)))
# 2) Escolher K e rodar o KNN ------------------------------------------------
k <- 5
pred_k <- knn(
train = X_train,   # base de treino (preditores)
test  = X_test,    # base de teste  (preditores)
cl    = y_train,   # classes de treino (factor)
k     = k          # número de vizinhos
)
# 3) Avaliar (matriz de confusão e acurácia) ---------------------------------
conf_k <- table(Predito = pred_k, Real = y_test)
acc_k  <- mean(pred_k == y_test)
conf_k
acc_k
View(glass_df_res)
library(class)
library(dplyr)
set.seed(42)   # reprodutibilidade
# --- 0) Conferência do dataset ---------------------------------------------
stopifnot(exists("glass_df_res"))   # dataset já pré-processado
target_col <- "Class"
stopifnot(target_col %in% names(glass_df_res))
# Garante que a classe é factor
glass_df_res[[target_col]] <- as.factor(glass_df_res[[target_col]])
# --- 1) Split estratificado 70/30 ------------------------------------------
split_ratio <- 0.7
idx_treino <- glass_df_res %>%
mutate(row_id = dplyr::row_number()) %>%
group_by(.data[[target_col]]) %>%
slice_sample(prop = split_ratio) %>%
pull(row_id)
train_df <- glass_df_res[idx_treino, ]
test_df  <- glass_df_res[-idx_treino, ]
# --- 2) Matriz de preditores e vetor de classe ------------------------------
X_train <- train_df %>% select(-all_of(target_col)) %>% as.data.frame()
X_test  <- test_df  %>% select(-all_of(target_col)) %>% as.data.frame()
y_train <- train_df[[target_col]]
y_test  <- test_df[[target_col]]
stopifnot(is.factor(y_train), is.factor(y_test))
stopifnot(all(sapply(X_train, is.numeric)), all(sapply(X_test, is.numeric)))
# --- 3) Rodar KNN -----------------------------------------------------------
k <- 5
pred_k <- knn(
train = X_train,
test  = X_test,
cl    = y_train,
k     = k,
)
# --- 4) Avaliar -------------------------------------------------------------
conf_k <- table(Predito = pred_k, Real = y_test)
acc_k  <- mean(pred_k == y_test)
conf_k
acc_k
