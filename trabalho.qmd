---
title: "trabalho"
format:
  pdf:
    pdf-engine: lualatex # bom para PT-BR e acentos
    toc: true
    number-sections: true
    code-overflow: wrap
lang: pt-BR
author: 
  - "Hanny Araujo Borges - 12221BSI249"
  - "Igor Melo Mesquita - 12221BSI206"
  - "Maria Eduarda Dutra Silva - 12221BSI228"
---

```{r}
library(readxl)
library(data.table)
library(ggplot2)
library(dplyr)
library(nnet)
library(rpart)
library(caret)
library(class)
```

# Introdução e Objetivos

A área de Ciência de Dados tem se mostrado fundamental para a extração de conhecimento e suporte à tomada de decisão a partir de grandes volumes de dados. Dentro deste campo, a classificação supervisionada se destaca como uma das tarefas mais comuns e importantes, permitindo a categorização de novos dados em classes pré-definidas com base em um conjunto de dados previamente rotulado. A escolha do algoritmo de classificação e seu correto ajuste são etapas cruciais que impactam diretamente o desempenho e a precisão do modelo final.

Este trabalho, realizado no âmbito da disciplina de Ciência de Dados, tem como objetivo principal aplicar, avaliar e interpretar o desempenho de diferentes algoritmos de classificação supervisionada. Para isso, serão utilizadas duas bases de dados públicas com características distintas: o *Dry Bean Dataset* e o *Glass Identification Dataset*.

# Descrição das Bases de Dados

Para a realização deste estudo, foram selecionadas duas bases de dados públicas, que são descritas a seguir.

## Dry Bean Dataset

Esta base de dados foi obtida a partir de um estudo que utilizou um sistema de visão computacional para extrair características de imagens de grãos de feijão. O objetivo é classificar os grãos em sete variedades diferentes.

-   Link para a fonte: <https://www.kaggle.com/datasets/joebeachcapital/dry-beans>

-   Descrição Geral:

-   Número de Instâncias: 13.611.

-   Número de Atributos: 17 (16 atributos previsores e 1 atributo classe).

-   Atributo Classe: *Class* (contendo 7 tipos de feijão: *Barbunya, Bombay, Cali, Dermason, Horoz, Seker* e *Sira*).

-   Valores Ausentes: A base de dados não possui valores ausentes.

-   Tipos de Atributos: Os atributos são numéricos (inteiros e reais), representando medidas extraídas das imagens dos grãos, como área, perímetro, comprimento dos eixos principal e menor, e outros fatores de forma. Sendo eles:

    -   Área (A): A área de um feijão e o número de pixels dentro de seus limites. à Contínuo

    -   Perímetro (P): Tamanho da borda do feijão. à Contínuo

    -   Comprimento do eixo principal (L): Definido pela distância das extremidades da linha mais longa a ser desenhada a partir de um feijão. à Contínuo

    -   Comprimento do eixo menor (l): Definido pela linha mais longa que pode ser traçada a partir do feijão, mantendo-se perpendicular ao eixo principal. à Contínuo

    -   Proporção (K): Define a relação entre os atributos L e l. à Contínuo

    -   Excentricidade (Ec): Excentricidade da elipse que possui os mesmos momentos da região. à Contínuo

    -   Área convexa (C): Número de pixels no menor polígono convexo capaz de conter a área da semente de feijão. à Discreto

    -   Diâmetro equivalente (Ed): Diâmetro de um círculo que possui a mesma área que a área da semente de feijão. à Contínuo

    -   Extensão (Ex): Razão entre o número de pixels do retângulo delimitador e a área da semente. à Contínuo

    -   Solidez (S): Também conhecido como convexidade. É a razão entre o número de pixels na casca convexa e os encontrados na semente. à Contínuo

    -   Circularidade (R): Quão circular é a forma, calculada pela fórmula que utiliza área (A) e perímetro (P). à Contínuo

        -   R=(4πA)/ P2

    -   Compacidade (CO): Mede o grau de arredondamento de um objeto, definido pela fórmula que une diâmetro (Ed) e maior eixo (L). à Contínuo

        -   CO = Ed/L

    -   Fator de Forma 1 (SF1), Fator de Forma 2 (SF2), Fator de Forma 3 (SF3), Fator de Forma 4 (SF4): Representam diferentes combinações matemáticas de área, perímetro e diâmetro para caracterizar a forma da semente. à Contínuo 

    -   Classe: Categoria da semente de feijão (S*eker, Barbunya, Bombay, Cali, Dermosan, Horoz* e *Sira*). à Categórico

Observando os dados da classe, é perceptível um desbalanceamento entre as categorias de feijão, sendo a classe *Dermason* a de maior peso. Em contrapartida, a classe *Bombay* se encontra em desvantagem, por ter a menor das representações.

```{r}
bean_df <- read_excel("Dry_Bean_Dataset.xlsx")
bean_df <- as.data.table(bean_df)   # se quiser table/dt

df <- bean_df %>% 
  group_by(Class)%>% 
  count(n())

ggplot(df, aes(x = Class, y = n, fill = Class)) +
  geom_col() +
  labs(title = "Distribuição das Classes de Feijão",
       x = "Classe",
       y = "Frequência") +
  theme_minimal()
```

## Glass Identification Dataset

Esta base de dados foi criada para investigações de ciência forense, onde fragmentos de vidro encontrados em cenas de crime podem ser usados como evidência se corretamente identificados. A classificação se baseia na composição química do vidro.

-   Link para a fonte: <https://archive.ics.uci.edu/dataset/42/glass+identification>

-   Descrição Geral:

-   Número de Instâncias: 214.

-   Número de Atributos: 11 (10 atributos previsores e 1 atributo classe).

-   Atributo Classe: *Type_of_glass* (com 7 tipos possíveis, embora um deles não tenha instâncias na base, resultando em 6 classes efetivas).

-   Valores Ausentes: A base de dados não possui valores ausentes.

-   Tipos de Atributos: Os atributos são numéricos contínuos, representando o índice de refração (RI) e a porcentagem em peso de óxidos de diferentes elementos químicos (Sódio, Magnésio, Alumínio, etc.). Sendo eles:

    -   Id_number: número identificador. à Discreto

    -   RI: Índice de refração. à Contínuo

    -   Na: Percentual em peso de sódio. à Contínuo

    -   Mg: Percentual em peso de magnésio. à Contínuo

    -   Al: Percentual em peso de alumínio. à Contínuo

    -   Si: Percentual em peso de silício. à Contínuo

    -   K: Percentual em peso de potássio. à Contínuo

    -   Ca: Percentual em peso de cálcio. à Contínuo

    -   Ba: Percentual em peso de bário. à Contínuo

    -   Fe: Percentual em peso de ferro. à Contínuo

    -   Classe:

1.  Janelas de edifícios - *float*

2.  Janelas de edifícios - não *float*

3.  Janelas de veículos - *float*

4.  Janelas de veículos - não *float* (sem amostras na base)

5.  Recipientes

6.  Utensílios de mesa

7.  Faróis de veículos

**Nota:** O termo “*float*” se refere à técnica de produção do vidro, onde uma camada fundida é nivelada sobre um banho de metal líquido que resulta num vidro uniforme e de superfície regular. Seu diferencial em relação ao método de “não *float*” está no índice de refração do material.

A base escolhida é desbalanceada, não contendo representação da classe 4 (janelas de veículos não *float*), e contendo discrepâncias de representação das demais classes, como ilustra o gráfico.

```{r}
glass_df <- fread("glass.data", sep = ",", header = FALSE)
colnames(glass_df) <- c(
  "Id_number",
  "RI",  # V2
  "Na",               # V3
  "Mg",               # V4
  "Al",               # V5
  "Si",               # V6
  "K",                # V7
  "Ca",               # V8
  "Ba",               # V9
  "Fe",               # V10
  "Class"             # V11
)

df <- glass_df %>% 
  group_by(Class)%>% 
  count(n()) %>% 
  mutate(Class = recode(Class,
                        `1` = "Janelas de edifícios (float)",
                        `2` = "Janelas de edifícios (não-float)",
                        `3` = "Janelas de veículos (float)",
                        `4` = "Janelas de veículos (não-float)",   # não há amostras
                        `5` = "Recipientes",
                        `6` = "Utensílios de mesa",
                        `7` = "Faróis"
  )) 



ggplot(df, aes(x = Class, y = n, fill = Class)) +
  geom_col() +
  labs(title = "Distribuição das Classes de Vidro",
       x = "Classe",
       y = "Frequência") +
  theme_minimal()
```

# Ferramenta

# Dry Bean Dataset

## Pré-processamento

Na base Dry Beans, que contém 13.611 instâncias e 16 atributos numéricos derivados de medidas geométricas das sementes, foram aplicadas três etapas principais de pré-processamento: amostragem, redução de dimensionalidade e transformação de variáveis.

### Amostragem

A amostragem foi considerada na base Dry Beans devido ao grande número de instâncias (13.611), permitindo reduzir o custo computacional durante os experimentos e possibilitando a execução de testes preliminares com subconjuntos menores de dados, garantindo maior eficiência na comparação entre classificadores. Optou-se pela amostragem estratificada, de modo a preservar as proporções originais das sete classes de feijões no subconjunto selecionado, o que se mostra essencial diante do desbalanceamento existente entre as classes, já que algumas variedades possuem muito mais instâncias que outras. Assim, essa estratégia assegura que o conjunto reduzido de dados mantenha a diversidade e representatividade necessárias para uma avaliação consistente do desempenho dos algoritmos de classificação.

```{r}
frac_global <- 0.03  # define o tamanho da partição para 3% do dataset

bean_df_bal <- bean_df %>%
  group_by(Class) %>% 
  slice_sample(prop = frac_global) %>% # realiza a partiçao da amostragem
  ungroup()


# Garantia de manutenção das proporções
df <- bean_df_bal %>% 
  group_by(Class)%>% 
  count(n())

ggplot(df, aes(x = Class, y = n, fill = Class)) +
  geom_col() +
  labs(title = "Distribuição das Classes de Feijão",
       x = "Classe",
       y = "Frequência") +
  theme_minimal()
```

### Redução de Dimensionalidade

Na redução de dimensionalidade, observou-se que diversos atributos da base são derivados de outros já existentes, apresentando, portanto, redundância. Por exemplo, o atributo *AspectRation* é calculado a partir da razão entre *MajorAxisLength* e *MinorAxisLength*, enquanto *Roundness* e *Compactness* utilizam *Area* e *Perimeter* em suas fórmulas. Dessa forma, optou-se por manter os atributos derivados e remover os fundamentais. Essa abordagem preserva a informação essencial em métricas normalizadas e reduz a redundância entre variáveis, conforme ilustrado na tabela apresentada nesta seção.

```{r}
# Retirada das colunas fundamentais 
bean_df_bal <- bean_df_bal %>% 
  select(-c("MinorAxisLength", "MajorAxisLength", "Area", "Perimeter", "ConvexArea"))
```

### Normalização

No processo de pré-processamento dos dados, adotou-se a normalização das variáveis preditoras, etapa fundamental para a execução de algoritmos de classificação baseados em medidas de distância e em modelos estatísticos multivariados. Foram utilizadas duas abordagens distintas conforme a necessidade de cada algoritmo: a normalização por re-escala e a padronização. A normalização por re-escala transforma os atributos para um intervalo comum, tipicamente \[0, 1\], evitando que variáveis com grande amplitude numérica dominem o cálculo das distâncias, como ocorre no KNN. Já a padronização converte cada atributo para média zero e desvio-padrão unitário, garantindo comparabilidade em algoritmos como a regressão logística, que assumem variáveis centradas e na mesma escala. Dessa forma, a aplicação dessas técnicas assegurou que todos os atributos contribuíssem de forma equilibrada no processo de classificação, aumentando a robustez e a interpretabilidade dos resultados obtidos.

#### Re-escalar

Normalização utilizada para o algoritmo KNN.

```{r}
min_max_normalization <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# Aplicando normalização (re-escala) nas colunas numéricas
bean_df_res <- bean_df_bal %>% 
  mutate(across(c("AspectRation", "Eccentricity", "EquivDiameter", "Extent", "Solidity", "roundness", "Compactness", "ShapeFactor1", "ShapeFactor2", "ShapeFactor3", "ShapeFactor4"), min_max_normalization))

bean_df_res %>% 
  select(
    AspectRation, 
    Eccentricity, 
    EquivDiameter, 
    Extent, 
    Solidity, 
    roundness, 
    Compactness, 
    ShapeFactor1, 
    ShapeFactor2, 
    ShapeFactor3, 
    ShapeFactor4
  )
```

#### Padronização

Normalização utilizada para o algoritmo Regressão Logística.

```{r}
padronization_norm <- function(x){
  return((x-mean(x))/sd(x))
}

# Aplicando normalização (padronização) nas colunas numéricas
bean_df_pad <- bean_df_res %>% 
  mutate(across(c("AspectRation", "Eccentricity", "EquivDiameter", "Extent", "Solidity", "roundness", "Compactness", "ShapeFactor1", "ShapeFactor2", "ShapeFactor3", "ShapeFactor4"), padronization_norm))

bean_df_pad %>% 
  select(
    AspectRation, 
    Eccentricity, 
    EquivDiameter, 
    Extent, 
    Solidity, 
    roundness, 
    Compactness, 
    ShapeFactor1, 
    ShapeFactor2, 
    ShapeFactor3, 
    ShapeFactor4
  )
```

## Estratégia da Divisão da Base de Dados

Adotou-se a estratégia de divisão Holdout para a separação dos dados em treino e teste. Essa técnica consiste em particionar a base em dois subconjuntos mutuamente exclusivos: um destinado ao treinamento do modelo e outro reservado para a sua avaliação. Optou-se por utilizar aproximadamente 2/3 dos dados para o treino e 1/3 para o teste, de modo a garantir que o classificador tivesse acesso a uma quantidade suficiente de instâncias para o aprendizado, ao mesmo tempo em que fosse avaliado em exemplos não vistos durante o treinamento. Essa abordagem permite estimar o desempenho do modelo de forma direta e eficiente, sendo amplamente utilizada em cenários com bases de dados de tamanho moderado.

```{r}
# ----- Exemplo de como foi incluído o Holdout nos algoritmos -----
# slice_sample(prop = 2/3) # Realiza a partição da base para treino e teste em 2/3, sendo 2/3 para treino e 1/3 para teste
```

## Algoritmos

### Árvore de Decisão

```{r}
set.seed(42)  # Reprodutibilidade

stopifnot(exists("bean_df_res")) # Verifica se o dataset existe
stopifnot('Class' %in% names(bean_df_res)) # Verifica se a classe existe
bean_df_res$Class <- as.factor(bean_df_res$Class) # Garante que a classe é factor

# Índices por classe
idx_treino_dt_bean <- bean_df_res %>%
  mutate(row_id = dplyr::row_number()) %>%
  group_by(Class) %>%
  slice_sample(prop = 2/3) %>% # Realiza a partição da base para treino e teste
  pull(row_id)

train_dt_bean <- bean_df_res[idx_treino_dt_bean, ]
test_dt_bean  <- bean_df_res[-idx_treino_dt_bean, ]

# Fórmula: alvo ~ todos os preditores
form_dt_bean <- reformulate(setdiff(names(train_dt_bean), 'Class'), response = 'Class')

# Executar Árvore de Decisão para cp = 0.01
cp_001_dt_bean  <- rpart(form_dt_bean, data = train_dt_bean, method = "class", control = rpart.control(cp = 0.01))
pred_001_dt_bean  <- predict(cp_001_dt_bean,  newdata = test_dt_bean, type = "class")

# Executar Árvore de Decisão para cp = 0.005
cp_0005_dt_bean <- rpart(form_dt_bean, data = train_dt_bean, method = "class", control = rpart.control(cp = 0.005))
pred_0005_dt_bean <- predict(cp_0005_dt_bean, newdata = test_dt_bean, type = "class")
```

### KNN

```{r}
set.seed(42) # Reprodutibilidade

stopifnot(exists("bean_df_res")) # Verifica se o dataset existe
stopifnot('Class' %in% names(bean_df_res)) # Verifica se a classe existe
bean_df_res$Class <- as.factor(bean_df_res$Class) # Garante que a classe é factor

# Índices por classe
idx_treino_knn_bean <- bean_df_res %>%
  mutate(row_id = dplyr::row_number()) %>%
  group_by(Class) %>%
  slice_sample(prop = 2/3) %>% # Realiza a partição da base para treino e teste
  pull(row_id)

train_knn_bean <- bean_df_res[idx_treino_knn_bean, ]
test_knn_bean  <- bean_df_res[-idx_treino_knn_bean, ]

# Matriz de preditores (x) e vetores de classe (y)
X_train_knn_bean <- train_knn_bean %>%
  select(-all_of('Class')) %>% 
  as.data.frame()

X_test_knn_bean  <- test_knn_bean %>% 
  select(-all_of('Class')) %>% 
  as.data.frame()

y_train_knn_bean <- train_knn_bean$Class
y_test_knn_bean <- test_knn_bean$Class

stopifnot(is.factor(y_train_knn_bean), is.factor(y_test_knn_bean)) # Verifica se todos os valores são factor (exigido pelo KNN)
stopifnot(all(sapply(X_train_knn_bean, is.numeric)), all(sapply(X_test_knn_bean, is.numeric))) # Verifica se todos os valores são numéricos (exigido pelo KNN)

# Executar KNN para k = 3
k_3_knn_bean <- 3 # Define a quantidade de K-vizinhos mais próximos

pred_k_3_knn_bean <- knn(
  train = X_train_knn_bean,   # base de treino (preditores)
  test  = X_test_knn_bean,    # base de teste  (preditores)
  cl    = y_train_knn_bean,   # classes de treino (factor)
  k     = k_3_knn_bean       # número de vizinhos
)

# Executar KNN para k = 5
k_5_knn_bean <- 5 # Define a quantidade de K-vizinhos mais próximos

pred_k_5_knn_bean <- knn(
  train = X_train_knn_bean,   # base de treino (preditores)
  test  = X_test_knn_bean,    # base de teste  (preditores)
  cl    = y_train_knn_bean,   # classes de treino (factor)
  k     = k_5_knn_bean        # número de vizinhos
)
```

### Regressão Logística

```{r}
set.seed(42)
 
# Índices por classe
idx_treino_rl_bean <- bean_df_pad %>%
  mutate(row_id = dplyr::row_number()) %>%
  group_by(Class) %>%
  slice_sample(prop = 2/3) %>% # Realiza a partição da base para treino e teste
  pull(row_id)


train_rl_bean <- bean_df_res[idx_treino_knn_bean, ]
test_rl_bean  <- bean_df_res[-idx_treino_knn_bean, ]


model_rl_bean <- multinom(Class ~ AspectRation + Eccentricity + EquivDiameter + Extent + Solidity + roundness + Compactness + ShapeFactor1 + ShapeFactor2 + ShapeFactor3 + ShapeFactor4, data = train_rl_bean)
 
coefs <- summary(model_rl_bean)$coefficients # pesos atribuidos a cada atributo de acordo com a classe
 
prediction_rl_bean <- predict(model_rl_bean, newdata = test_rl_bean)
```

Para testagem do desempenho do modelo com outros parâmetros, testaremos o treinamento apenas com os atributos mais relevantes para cada classe, baseado nos pesos a elas atribuídos.

```{r}
# Converter os coeficientes em um data frame para facilitar a manipulação
coefs_df <- as.data.frame(coefs)
# Calcular os coeficientes absolutos
coefs_abs <- abs(coefs_df)
# Para cada variável (linha), pegar o maior valor absoluto e associar à variável
max_values <- apply(coefs_abs, 1, max)
# Agora associamos os valores máximos às variáveis (colunas)
max_vars <- apply(coefs_abs, 1, function(x) names(x)[which.max(x)])
# Criar um data frame para mostrar os atributos associados aos maiores valores
important_vars <- data.frame(Variable = max_vars, MaxValue = max_values)
# Ordenar pelas variáveis com maior coeficiente absoluto
important_vars_sorted <- important_vars[order(-important_vars$MaxValue), ]
# Mostrar as variáveis mais importantes
head(important_vars_sorted)
 
model_rl_bean_less_att <- multinom(Class ~  EquivDiameter + roundness + ShapeFactor1 + ShapeFactor4, data = train_rl_bean)
coefs_bean_less_att <- summary(model_rl_bean_less_att)$coefficients # pesos atribuidos a cada atributo de acordo com a classe
prediction_rl_bean_less_att <- predict(model_rl_bean_less_att, newdata = test_rl_bean)
```

## Medidas de Avaliação

Para a avaliação dos classificadores, foram utilizadas duas medidas principais: a matriz de confusão e a acurácia. A matriz de confusão consiste em uma tabela que organiza as previsões do modelo em relação aos valores reais, discriminando corretamente os acertos e os erros de classificação para cada classe. A acurácia, por sua vez, expressa a proporção de instâncias corretamente classificadas pelo modelo em relação ao total de instâncias avaliadas, sendo calculada pela fórmula:

Acurácia = (TP + TN) / (TP + TN + FP + FN)

em que TP (true positive) e TN (true negative) representam as previsões corretas, enquanto FP (false positive) e FN (false negative) correspondem às classificações incorretas.

```{r}
# -------------------- Árvore de Decisão --------------------

# Avaliar | cp = 0.01
cm_001_dt_bean <- confusionMatrix(pred_001_dt_bean, test_dt_bean$Class)
acc_001_dt_bean  <- cm_001_dt_bean$overall["Accuracy"]

cm_001_dt_bean
acc_001_dt_bean

# Avaliar | cp = 0.005
cm_0005_dt_bean <- confusionMatrix(pred_0005_dt_bean, test_dt_bean$Class)
acc_0005_dt_bean <- cm_0005_dt_bean$overall["Accuracy"]

cm_0005_dt_bean
acc_0005_dt_bean
```

```{r}
# -------------------- KNN --------------------

# Avaliar | k = 3
conf_k_3_knn_bean <- table(Predito = pred_k_3_knn_bean, Real = y_test_knn_bean)
acc_k_3_knn_bean  <- mean(pred_k_3_knn_bean == y_test_knn_bean)

conf_k_3_knn_bean
acc_k_3_knn_bean

# Avaliar | k = 5
conf_k_5_knn_bean <- table(Predito = pred_k_5_knn_bean, Real = y_test_knn_bean)
acc_k_5_knn_bean  <- mean(pred_k_5_knn_bean == y_test_knn_bean)

conf_k_5_knn_bean
acc_k_5_knn_bean
```

```{r}
# -------------------- Regressão Logística --------------------

# Avaliar | todas as classes
conf_rl_bean <- table(Predito = prediction_rl_bean, Real = test_rl_bean$Class)
acc_rl_bean  <- mean(prediction_rl_bean == test_rl_bean$Class)

conf_rl_bean
acc_rl_bean

# Avaliar | apenas classes mais importantes (baseado no modelo que usa todas as classes)
conf_rl_bean <- table(Predito = prediction_rl_bean_less_att, Real = test_rl_bean$Class)
acc_rl_bean  <- mean(prediction_rl_bean_less_att == test_rl_bean$Class)

conf_rl_bean
acc_rl_bean
```

# Glass Identification Dataset

## Pré-processamento

Na base Glass Identification, composta por 214 instâncias e 9 atributos numéricos, foram aplicadas duas etapas principais de pré-processamento: seleção de atributos e transformação de variáveis.

### Seleção de Atributos

Na seleção de atributos, foi realizada a remoção do campo *Id_number*, uma vez que esse atributo não possui relevância para a classificação e poderia introduzir ruído no modelo.

```{r}
glass_df <- glass_df %>% 
  select(-Id_number)
```

### Normalização

No processo de pré-processamento dos dados, adotou-se a normalização das variáveis preditoras, etapa fundamental para a execução de algoritmos de classificação baseados em medidas de distância e em modelos estatísticos multivariados. Foram utilizadas duas abordagens distintas conforme a necessidade de cada algoritmo: a normalização por re-escala e a padronização. A normalização por re-escala transforma os atributos para um intervalo comum, tipicamente \[0, 1\], evitando que variáveis com grande amplitude numérica dominem o cálculo das distâncias, como ocorre no KNN. Já a padronização converte cada atributo para média zero e desvio-padrão unitário, garantindo comparabilidade em algoritmos como a regressão logística, que assumem variáveis centradas e na mesma escala. Dessa forma, a aplicação dessas técnicas assegurou que todos os atributos contribuíssem de forma equilibrada no processo de classificação, aumentando a robustez e a interpretabilidade dos resultados obtidos.

#### Re-escalar

Normalização utilizada para o algoritmo KNN.

```{r}
glass_df_res <- glass_df %>% 
  mutate(across(c("RI","Na","Mg","Al","Si","K","Ca","Ba","Fe"), min_max_normalization))

glass_df_res %>% 
  select(-Class)
```

#### Padronização

Normalização utilizada para o algoritmo Regressão Logística.

```{r}
glass_df_pad <- glass_df %>% 
  mutate(across(c("RI","Na","Mg","Al","Si","K","Ca","Ba","Fe"), padronization_norm))

glass_df_pad %>% 
  select(-Class)
```

## Estratégia da Divisão da Base de Dados

Adotou-se a estratégia de divisão Holdout para a separação dos dados em treino e teste. Essa técnica consiste em particionar a base em dois subconjuntos mutuamente exclusivos: um destinado ao treinamento do modelo e outro reservado para a sua avaliação. Optou-se por utilizar aproximadamente 2/3 dos dados para o treino e 1/3 para o teste, de modo a garantir que o classificador tivesse acesso a uma quantidade suficiente de instâncias para o aprendizado, ao mesmo tempo em que fosse avaliado em exemplos não vistos durante o treinamento. Essa abordagem permite estimar o desempenho do modelo de forma direta e eficiente, sendo amplamente utilizada em cenários com bases de dados de tamanho moderado.

```{r}
# ----- Exemplo de como foi incluído o Holdout nos algoritmos -----
# slice_sample(prop = 2/3) # Realiza a partição da base para treino e teste em 2/3, sendo 2/3 para treino e 1/3 para teste
```

## Algoritmos

### Árvore de Decisão

```{r}
set.seed(42)  # Reprodutibilidade

stopifnot(exists("glass_df_res")) # Verifica se o dataset existe
stopifnot('Class' %in% names(glass_df_res)) # Verifica se a classe existe
glass_df_res$Class <- as.factor(glass_df_res$Class) # Garante que a classe é factor

# Índices por classe
idx_treino_dt_glass <- glass_df_res %>%
  mutate(row_id = dplyr::row_number()) %>%
  group_by(Class) %>%
  slice_sample(prop = 2/3) %>% # Realiza a partição da base para treino e teste
  pull(row_id)

train_dt_glass <- glass_df_res[idx_treino_dt_glass, ]
test_dt_glass  <- glass_df_res[-idx_treino_dt_glass, ]

# Fórmula: alvo ~ todos os preditores
form_dt_glass <- reformulate(setdiff(names(train_dt_glass), 'Class'), response = 'Class')

# Treinar duas árvores com cp diferentes
cp_001_dt_glass  <- rpart(form_dt_glass, data = train_dt_glass, method = "class", control = rpart.control(cp = 0.01))
cp_0005_dt_glass <- rpart(form_dt_glass, data = train_dt_glass, method = "class", control = rpart.control(cp = 0.005))

# Prever no conjunto de teste
pred_001_dt_glass  <- predict(cp_001_dt_glass,  newdata = test_dt_glass, type = "class")
pred_0005_dt_glass <- predict(cp_0005_dt_glass, newdata = test_dt_glass, type = "class")
```

### KNN

```{r}
set.seed(42) # Reprodutibilidade

stopifnot(exists("glass_df_res")) # Verifica se o dataset existe
stopifnot('Class' %in% names(glass_df_res)) # Verifica se a classe existe
glass_df_res$Class <- as.factor(glass_df_res$Class) # Garante que a classe é factor

# Índices por classe
idx_treino_knn_glass <- glass_df_res %>%
  mutate(row_id = dplyr::row_number()) %>%
  group_by(Class) %>%
  slice_sample(prop = 2/3) %>% # Realiza a partição da base para treino e teste
  pull(row_id)

train_knn_glass <- glass_df_res[idx_treino_knn_glass, ]
test_knn_glass  <- glass_df_res[-idx_treino_knn_glass, ]

# Matriz de preditores (x) e vetores de classe (y)
X_train_knn_glass <- train_knn_glass %>% select(-all_of('Class')) %>% as.data.frame()
X_test_knn_glass  <- test_knn_glass  %>% select(-all_of('Class')) %>% as.data.frame()

y_train_knn_glass <- train_knn_glass$Class
y_test_knn_glass  <- test_knn_glass$Class

stopifnot(is.factor(y_train_knn_glass), is.factor(y_test_knn_glass)) # Verifica se todos os valores são factor (exigido pelo KNN)
stopifnot(all(sapply(X_train_knn_glass, is.numeric)), all(sapply(X_test_knn_glass, is.numeric))) # Verifica se todos os valores são numéricos (exigido pelo KNN)

# Executar KNN para k = 3
k_3_knn_glass <- 3 # Define a quantidade de K-vizinhos mais próximos

pred_k_3_knn_glass <- knn(
  train = X_train_knn_glass,
  test  = X_test_knn_glass,
  cl    = y_train_knn_glass,
  k     = k_3_knn_glass
)

# Executar KNN para k = 5
k_5_knn_glass <- 5 # Define a quantidade de K-vizinhos mais próximos

pred_k_5_knn_glass <- knn(
  train = X_train_knn_glass,
  test  = X_test_knn_glass,
  cl    = y_train_knn_glass,
  k     = k_5_knn_glass
)
```

### Regressão Logística

```{r}
set.seed(42)
# Definido partição de treino
idx_treino_rl_glass <- glass_df_pad %>%
  mutate(row_id = dplyr::row_number()) %>%
  group_by(Class) %>%
  slice_sample(prop = 2/3) %>% # Realiza a partição da base para treino e teste
  pull(row_id)
train_rl_glass <- glass_df_res[idx_treino_rl_glass, ]
test_rl_glass <- glass_df_res[-idx_treino_rl_glass, ]
 
 
model <- multinom(Class ~ RI + Na + Mg + Al + Si + K + Ca + Ba + Fe, data = train_rl_glass)
coefs <- summary(model)$coefficients # pesos atribuidos a cada atributo de acordo com a classe
prediction_rl_glass <- predict(model, newdata = test_rl_glass)
```

Para testagem do desempenho do modelo com outros parâmetros, testaremos o treinamento apenas com os atributos mais relevantes para cada classe, baseado nos pesos a elas atribuídos.

```{r}
# Converter os coeficientes em um data frame para facilitar a manipulação
coefs_df <- as.data.frame(coefs)
# Calcular os coeficientes absolutos
coefs_abs <- abs(coefs_df)
# Para cada variável (linha), pegar o maior valor absoluto e associar à variável
max_values <- apply(coefs_abs, 1, max)
# Agora associamos os valores máximos às variáveis (colunas)
max_vars <- apply(coefs_abs, 1, function(x) names(x)[which.max(x)])
# Criar um data frame para mostrar os atributos associados aos maiores valores
important_vars <- data.frame(Variable = max_vars, MaxValue = max_values)
# Ordenar pelas variáveis com maior coeficiente absoluto
important_vars_sorted <- important_vars[order(-important_vars$MaxValue), ]
# Mostrar as variáveis mais importantes
head(important_vars_sorted)
 
model_less_att <- multinom(Class ~ Mg + Al + K, data = train_rl_glass)
coefs_less_att <- summary(model_less_att)$coefficients # pesos atribuidos a cada atributo de acordo com a classe
prediction_rl_glass_less_att <- predict(model_less_att, newdata = test_rl_glass)
```

## Medidas de Avaliação

Para a avaliação dos classificadores, foram utilizadas duas medidas principais: a matriz de confusão e a acurácia. A matriz de confusão consiste em uma tabela que organiza as previsões do modelo em relação aos valores reais, discriminando corretamente os acertos e os erros de classificação para cada classe. A acurácia, por sua vez, expressa a proporção de instâncias corretamente classificadas pelo modelo em relação ao total de instâncias avaliadas, sendo calculada pela fórmula:

Acurácia = (TP + TN) / (TP + TN + FP + FN)

em que TP (true positive) e TN (true negative) representam as previsões corretas, enquanto FP (false positive) e FN (false negative) correspondem às classificações incorretas.

```{r}
# -------------------- Árvore de Decisão --------------------

# DRY BEAN
# Avaliar | cp = 0.01 -----> 0.5 (maior mais simples)
conf_001_dt_bean <- confusionMatrix(pred_001_dt_bean,test_dt_bean$Class)
acc_001_dt_bean <- mean(pred_001_dt_bean == test_dt_bean$Class)


# Avaliar | cp = 0.005 ------> (mais complexa)
conf_0005_dt_bean <- confusionMatrix(pred_0005_dt_bean,test_dt_bean$Class)
acc_0005_dt_bean <- mean(pred_0005_dt_bean == test_dt_bean$Class)

print(paste("A acurácia do dataset DRY BEAN é superior com cp = ", 
            ifelse(acc_001_dt_bean > acc_0005_dt_bean, 0.01, 0.005)
)
)


# GLASS IDENTIFICATION
# Avaliar | cp = 0.01 -----> 0.5 (maior mais simples)
conf_001_dt_glass  <- confusionMatrix(pred_001_dt_glass,  test_dt_glass$Class)
acc_001_dt_glass  <- mean(pred_001_dt_glass == test_dt_glass$Class)

# Avaliar | cp = 0.005 ------> (mais complexa)
conf_0005_dt_glass <- confusionMatrix(pred_0005_dt_glass, test_dt_glass$Class)
acc_0005_dt_glass <- mean(pred_0005_dt_glass == test_dt_glass$Class)

print(paste("A acurácia do dataset GLASS IDENTIFICATION é superior com cp = ", 
            ifelse(acc_001_dt_bean > acc_0005_dt_bean, 0.01, 0.005)
)
)

```

```{r}
# -------------------- KNN --------------------

# DRY BEAN
# Avaliar | k = 3
conf_k_3_knn_bean <- confusionMatrix(pred_k_3_knn_bean, y_test_knn_bean)
acc_k_3_knn_bean  <- mean(pred_k_3_knn_bean == y_test_knn_bean)

# Avaliar | k = 5
conf_k_5_knn_bean  <- confusionMatrix(pred_k_5_knn_bean, y_test_knn_bean)
acc_k_5_knn_bean   <- mean(pred_k_5_knn_bean == y_test_knn_bean)

print(paste("A acurácia do dataset DRY BEAN é superior com knn = ", 
            ifelse(acc_k_5_knn_bean > acc_k_3_knn_bean, 5, 3)
)
)


# GLASS IDENTIFICATION
# Avaliar | k = 3
conf_k_3_knn_glass <- confusionMatrix(pred_k_3_knn_glass, y_test_knn_glass)
acc_k_3_knn_glass  <- mean(pred_k_3_knn_glass == y_test_knn_glass)

# Avaliar | k = 5
conf_k_5_knn_glass <- confusionMatrix(pred_k_5_knn_glass, y_test_knn_glass)
acc_k_5_knn_glass  <- mean(pred_k_5_knn_glass == y_test_knn_glass)

print(paste("A acurácia do dataset GLASS IDENTIFICATION é superior com knn = ", 
            ifelse(acc_k_5_knn_glass > acc_k_3_knn_glass, 5, 3)
)
)
```

```{r}
# -------------------- Regressão Logística --------------------

# DRY BEAN
# Avaliar | todas as classes
conf_rl_bean <- confusionMatrix(prediction_rl_bean, test_rl_bean$Class)
acc_rl_bean  <- mean(prediction_rl_bean == test_rl_bean$Class)

# Avaliar | apenas classes mais importantes (baseado no modelo que usa todas as classes)
conf_rl_bean_less_att <- confusionMatrix(prediction_rl_bean_less_att,test_rl_bean$Class)
acc_rl_bean_less_att  <- mean(prediction_rl_bean_less_att == test_rl_bean$Class)

print(paste("A acurácia do dataset DRY BEAN é superior considerando ", 
            ifelse(acc_rl_bean > acc_rl_bean_less_att, "todos os atributos", "apenas os atributos selecionados")
)
)

# GLASS IDENTIFICATION
# Avaliar | todas as classes
conf_rl_glass <- confusionMatrix(prediction_rl_glass, test_rl_glass$Class)
acc_rl_glass  <- mean(prediction_rl_glass == test_rl_glass$Class)

# Avaliar | apenas classes mais importantes (baseado no modelo que usa todas as classes)
conf_rl_glass_less_att <- confusionMatrix(prediction_rl_glass_less_att,test_rl_glass$Class)
acc_rl_glass_less_att  <- mean(prediction_rl_glass_less_att == test_rl_glass$Class)

print(paste("A acurácia do dataset GLASS IDENTIFICATION é superior considerando ", 
            ifelse(acc_rl_glass > acc_rl_glass_less_att, "todos os atributos", "apenas os atributos selecionados")
)
)
```

# Resultados

```{r}
comparative_table_glass <- data.frame(
  Dataset = "Glass Identification",
  Classificator = c("Arvore de Decisão", "KNN", "Regressão Logística"),
  Accuracy = c(acc_0005_dt_glass,acc_k_3_knn_glass, acc_rl_glass)
)

comparative_table_bean <- data.frame(
  Dataset = "Dry Bean",
  Classificator = c("Arvore de Decisão", "KNN", "Regressão Logística"),
  Accuracy = c(acc_0005_dt_bean,acc_k_5_knn_glass, acc_rl_bean_less_att)
)

comparative_table <- comparative_table_bean %>% 
  union(comparative_table_glass)

comparative_table
```

Matrizes de confusão

```{r}
plot_matrix <- function(data, nome){
  ggplot(data, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile() +
  facet_wrap(~ model) + # Adiciona uma faceta para cada modelo
  scale_fill_gradient(low = "white", high = "blue") +
  theme_minimal() +
  labs(title = paste("Matrizes de Confusão ", nome, sep = ""), x = "Classe Real", y = "Classe Predita")
}
```

```{r}

# DRY BEANS

# Extrair os dados da matriz de confusão e definir modelos
cm_dt_bean <- as.data.frame(conf_0005_dt_bean$table)
cm_dt_bean$model <- "Arvore de Decisao"

cm_knn_bean <- as.data.frame(conf_k_3_knn_bean$table)
cm_knn_bean$model <- "KNN"

cm_rl_bean <- as.data.frame(conf_rl_bean$table)
cm_rl_bean$model <- "Regressao Logistica"

# Combinar as matrizes de confusão
cm_beans <- rbind(cm_dt_bean, cm_knn_bean, cm_rl_bean)


# Plotar as matrizes de confusão
plot_matrix(cm_dt_bean, "Dry Beans")
plot_matrix(cm_knn_bean, "Dry Beans")
plot_matrix(cm_rl_bean, "Dry Beans")
```

```{r}
# GLASS IDENTIFICATION

# Extrair os dados da matriz de confusão e definir modelos
cm_dt_glass <- as.data.frame(conf_0005_dt_glass$table)
cm_dt_glass$model <- "Arvore de Decisao"

cm_knn_glass <- as.data.frame(conf_k_3_knn_glass$table)
cm_knn_glass$model <- "KNN"

cm_rl_glass <- as.data.frame(conf_rl_glass$table)
cm_rl_glass$model <- "Regressao Logistica"

# Combinar as matrizes de confusão
cm_glasss <- rbind(cm_dt_glass, cm_knn_glass, cm_rl_glass)


# Plotar as matrizes de confusão
plot_matrix(cm_dt_glass, "Glass identification")
plot_matrix(cm_knn_glass, "Glass identification")
plot_matrix(cm_rl_glass, "Glass identification")
```
